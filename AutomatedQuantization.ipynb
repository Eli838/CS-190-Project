{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2624b95f-b43c-4c00-8db9-3567b32e57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2103275b-949c-4dc2-9017-84bed6a1cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_lengths = [8,7,6,5,4,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa408174-2f22-4451-8615-abe2ca715526",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('./Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d8d4b-8447-49f5-bbd4-20710532152e",
   "metadata": {},
   "source": [
    "# Initial Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa1fe09-0c97-42aa-a849-453422d7c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adab635-9208-4a61-b416-b5228dedece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc74ce06-32da-4381-8215-97bb36b1bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a7c0e9-c03d-48e2-8302-3e8677cd40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "    \n",
    "    alexnet.classifier[4] = nn.Linear(4096,1024)\n",
    "    alexnet.classifier[6] = nn.Linear(1024,10)\n",
    "    \n",
    "    alexnet.load_state_dict(torch.load('model_20240603_151633_final_frozen_alexnet',map_location=device))\n",
    "    alexnet.eval()\n",
    "    return alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16d918-639d-47cd-9b0f-485e3126d8ed",
   "metadata": {},
   "source": [
    "# Quantization Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc616867-88d2-4308-b916-8c73503391f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5157a69e-2101-466d-89c3-4bfc495fa8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import struct\n",
    "import torch.nn.init as init\n",
    "\n",
    "# EXP_COUNT = {0:0,\n",
    "#              1:0,\n",
    "#              2:0,\n",
    "#              3:0,\n",
    "#              4:0,\n",
    "#              5:0,\n",
    "#              6:0,\n",
    "#              7:0,\n",
    "#             }\n",
    "            \n",
    "# input : tensor output: binary string\n",
    "def binary(num):\n",
    "  return ''.join('{:0>8b}'.format(c) for c in struct.pack('!f', num))\n",
    "\n",
    "#input: mantissa bitstring\n",
    "#output: float value\n",
    "def calc_mantissa(mantissa):\n",
    "  res = 0\n",
    "  for k in range(len(mantissa)):\n",
    "      if mantissa[k] == '1':\n",
    "        res += 2**(-k-1)\n",
    "  return res\n",
    "\n",
    "#input exp: bitstring\n",
    "# new_exp_len: new length of exp\n",
    "def calc_exp(exp, new_exp_len):\n",
    "  limit = 2**(new_exp_len) - 1\n",
    "  # if exp is more than new_exp_len limit, truncate to new_exp_len limit.\n",
    "  bias = 2**(len(exp)-1) - 1\n",
    "  val = int(exp,2) - bias\n",
    "  if val > limit:\n",
    "      return limit\n",
    "  if val < -limit + 1:\n",
    "      return -limit + 1\n",
    "      pass\n",
    "  return val\n",
    "\n",
    "\n",
    "def round_fp8(x, exp = 4):\n",
    "  '''\n",
    "  Quantizes input tensor to FP8 data format\n",
    "  inputs  x:      original tensor\n",
    "          exp:    number of bits used for exponent field\n",
    "                  e.g. E5M2 has 5 exp bits, E4M3 has 4 exp bits\n",
    "  output  x_32:   quantized tensor\n",
    "  '''\n",
    "\n",
    "  x_fp8 = copy.deepcopy(x)\n",
    "\n",
    "\n",
    "  result = 1.0\n",
    "  bin_str = binary(x)\n",
    "\n",
    "  bin_mantissa = bin_str[9:32]\n",
    "  res_mantissa = bin_mantissa[:7-exp]\n",
    "  result += calc_mantissa(res_mantissa)\n",
    "\n",
    "  bin_exp = bin_str[1:9]\n",
    "  exp_int = calc_exp(bin_exp, exp)\n",
    "  result *= 2**exp_int\n",
    "\n",
    "  if bin_str[0] == '1':\n",
    "    result *= -1\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def bisection_quantization(num, bits = 7):\n",
    "    if bits == 0:\n",
    "        return 0.1\n",
    "    val = abs(num)\n",
    "    inversed_bits = []\n",
    "    # Bisection tree quantization\n",
    "    range_min, range_max = 0, 1\n",
    "    for p in range(bits):\n",
    "        p += 1\n",
    "        bit_val = 2**(-p)\n",
    "        if val >= bit_val:\n",
    "            inversed_bits.append(1)\n",
    "            val -= bit_val\n",
    "        else:\n",
    "            inversed_bits.append(0)\n",
    "\n",
    "    quantized_val = 0\n",
    "    for k, bit in enumerate(inversed_bits):\n",
    "        if bit:\n",
    "            quantized_val += 2**-(k + 1)\n",
    "    return quantized_val\n",
    "\n",
    "#the input is normalized tensor x,\n",
    "def round_dt8(x, exp = 4, num_bits = 8):\n",
    "  val = copy.deepcopy(x)\n",
    "\n",
    "  sign_bit = 0 if val >= 0 else 1\n",
    "  val = abs(val)\n",
    "  exp_bits = 0\n",
    "  while val < 0.1:\n",
    "      val *= 10\n",
    "      exp_bits += 1\n",
    "\n",
    "  bs_bits = max(0, num_bits - 2 - exp_bits)\n",
    "  exp_bits = min(num_bits -1, exp_bits)\n",
    "  EXP_COUNT[exp_bits] += 1\n",
    "\n",
    "  if exp_bits == 0:\n",
    "      quantized_val = bisection_quantization(val, 7)\n",
    "  elif exp_bits >= num_bits - 2:\n",
    "      quantized_val = 0.0\n",
    "  else:\n",
    "      quantized_val = bisection_quantization(val, bs_bits)\n",
    "\n",
    "  quantized_val = quantized_val if sign_bit == 0 else -quantized_val\n",
    "  quantized_val *= 10**(-exp_bits)\n",
    "  return quantized_val\n",
    "\n",
    "\n",
    "\n",
    "def quantize_rowwise(x: torch.Tensor, bits, dt = False):\n",
    "  '''Takes in a (2d) tensor and returns quantized array\n",
    "  DT = if you use the dynamic tree quantization. False is using fp8\n",
    "  tensor.view( shape[0],-1) can reshape a 3d tensor to 2d. that should work'''\n",
    "  abso = torch.abs(x)\n",
    "  output_maxs  = torch.max(abso,1)[0].unsqueeze(-1)\n",
    "  output = x  / output_maxs[None,:]\n",
    "  if not dt:\n",
    "      output.apply_(round_fp8)\n",
    "  else:\n",
    "      def dt_wrapper(x: torch.Tensor):\n",
    "        if bits < 4:\n",
    "            exp_bits = bits - 1\n",
    "        else:\n",
    "            exp_bits = 8\n",
    "        return round_dt8(x, num_bits = bits)\n",
    "      output.apply_(dt_wrapper)\n",
    "  return torch.squeeze(output), output_maxs\n",
    "\n",
    "def dequantize_rowwise(x: torch.Tensor, state_x: torch.Tensor):\n",
    "  '''Dequantizes the tensor given the maxes'''\n",
    "  output = x * state_x\n",
    "  return output\n",
    "\n",
    "def init_weights(m, in_std = 1.0):\n",
    "  if isinstance(m, nn.Linear):\n",
    "      init.normal_(m.weight, mean=0.0, std=in_std)\n",
    "      if m.bias is not None:\n",
    "          init.zeros_(m.bias)\n",
    "\n",
    "def measure_quantization_error(original_tensor, dequantized_tensor):\n",
    "  abs_error = torch.abs(original_tensor - dequantized_tensor)\n",
    "  return torch.mean(abs_error), abs_error\n",
    "\n",
    "\n",
    "def quantize_stable_embedding(x, batch_size, dt = False):\n",
    "  '''Qunatizes the given array\n",
    "  Batch size must be a divisor of the array size\n",
    "  Returns the quantized array, the maximums, and the indexes\n",
    "  DT  = false, means using fp8\n",
    "  Dt = true, means using the dynamic tree\n",
    "  '''\n",
    "  if (x.numel() % batch_size != 0):\n",
    "    print(\"Invalid batch size. Batch size should be a divisor of \" + str(x.numel()))\n",
    "    return\n",
    "\n",
    "  flatarg = torch.argsort(torch.abs(x.flatten()))\n",
    "  indexing = flatarg.reshape((x.numel()//batch_size,batch_size))\n",
    "\n",
    "  reshapedx = x.flatten()[indexing]\n",
    "\n",
    "  output, maxes = quantize_rowwise(reshapedx,dt)\n",
    "\n",
    "  return output.reshape(x.shape), maxes, indexing\n",
    "\n",
    "def dequantize_stable_embedding(input, maxes, indexing):\n",
    "  '''Takes the quantized matrices and dequantizes them by multiplying the normalized and maxes\n",
    "  Then uses the indexes to place the dequantized values back into their original spots\n",
    "  returns dequantized values in the right positions\n",
    "  Takes in the quantized array, the array maximums, and the indexes'''\n",
    "  outreshape = input.reshape(indexing.shape)\n",
    "\n",
    "  dequant = dequantize_rowwise(outreshape, maxes).flatten()\n",
    "  dequant[indexing.flatten()] = dequant.clone()\n",
    "  return dequant.reshape(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21fea19-cc9b-4a27-aa47-a8591fe8d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_dequantize_dt(mat,bits,output_path, layer_num):\n",
    "    # return quantize_rowwise(mat, dt = True)[0]\n",
    "    testing_dt, dt_max = quantize_rowwise(mat, bits, dt = True)\n",
    "    np.save(output_path / f'layer{count}_dt_max.npy',dt_max)\n",
    "    np.save(output_path / f'layer{count}_qweights.npy',testing_dt)\n",
    "    return dequantize_rowwise(testing_dt,dt_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8de25-64fb-49dc-bf8e-e0a4e64eb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_dequantize_fp8(mat):\n",
    "    testing_dt, dt_max = quantize_rowwise(mat, bits, dt = True)\n",
    "    np.save(output_path / f'layer{count}_dt_max.npy',dt_max)\n",
    "    np.save(output_path / f'layer{count}_qweights.npy',testing_dt)\n",
    "    return dequantize_rowwise(testing_dt,dt_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee85dd-0dd5-4f32-8633-ef2e4ed4bfda",
   "metadata": {},
   "source": [
    "# Automated Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee98b70f-beb2-44fa-8282-6abf3dce5a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Quantization: 7 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Elijah/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bit_length in bit_lengths:\n",
    "    print(f'DT Quantization: {bit_length} bits')\n",
    "    EXP_COUNT = {0:0,\n",
    "             1:0,\n",
    "             2:0,\n",
    "             3:0,\n",
    "             4:0,\n",
    "             5:0,\n",
    "             6:0,\n",
    "             7:0,\n",
    "            }\n",
    "    alexnet = create_model()\n",
    "    count = 0\n",
    "    curr_path = output_path / f'{bit_length}-bit-layers' \n",
    "    curr_path.mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "    for layer in [*alexnet.features,*alexnet.classifier]:\n",
    "        count += 1 \n",
    "        curr_layer_path = curr_path \n",
    "        try:\n",
    "            if len(layer.weight.shape) == 4:\n",
    "                weights = layer.weight.detach()\n",
    "                print(f'Layer {count}')# weights shape pre-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                for filter in range(0, weights.shape[0]):\n",
    "                    # print(f'Filter num {filter}')\n",
    "                    for channel in range(0, weights.shape[1]):\n",
    "                        # print(f'Channel num {channel}')\n",
    "                        # print(layer.weight[filter,channel])\n",
    "                        weights[filter,channel] = quantize_dequantize_dt(weights[filter,channel],bit_length, curr_layer_path, count)\n",
    "                        # for row in range(0,weights.shape[2]):\n",
    "                        #     weights[filter,channel, row] = quantize_dequantize_dt(weights[filter,channel,row])\n",
    "                        # print(f'Finish window')\n",
    "                # print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                # layer.weight = nn.parameter.Parameter(weights)\n",
    "                print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                layer.weight = nn.parameter.Parameter(weights)\n",
    "            else:\n",
    "                weights = layer.weight.detach()\n",
    "                print(f'Layer {count}')# weights shape pre-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "                weights = quantize_dequantize_dt(weights,bit_length,curr_layer_path, count)\n",
    "                # for row in tqdm(range(0,weights.shape[0])):\n",
    "                #     weights[row] = quantize_dequantize_dt(weights[row])\n",
    "                layer.weight = nn.parameter.Parameter(weights)\n",
    "                # print(f'Layer {count} weights shape post-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "                # print(layer.weight)\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "    model_path = output_path / f'dt_quantized_model_bl_{bit_length}'\n",
    "    count_path = output_path / f'dt_counts_bl_{bit_length}.pkl'\n",
    "    torch.save(alexnet.state_dict(), model_path)\n",
    "    with open(count_path, 'wb') as f:\n",
    "        pickle.dump(EXP_COUNT,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b310f86-1a28-482e-848a-bf3e80f8ad81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f76fe2-a2ba-404d-b880-b2bc5572064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c76131-abef-40de-b0bd-f4dd925bc691",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "USE_DT_FILE = False\n",
    "Test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b82153a-883e-4e0b-824e-a95acfedc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2824be-ba9e-4b6e-a513-9cc9c9e3a3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd064db-ca5a-4c2f-94df-2186d991295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Elijah/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "C:\\Users\\Elijah\\anaconda3\\envs\\cs190-project\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elijah\\anaconda3\\envs\\cs190-project\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "\n",
    "alexnet.classifier[4] = nn.Linear(4096,1024)\n",
    "alexnet.classifier[6] = nn.Linear(1024,10)\n",
    "if USE_DT_FILE:\n",
    "    alexnet.load_state_dict(torch.load('model_20240531_040442_DT_Quantized_NEW',map_location=device))\n",
    "else:\n",
    "    alexnet.load_state_dict(torch.load('model_20240525_150139_final',map_location=device))\n",
    "alexnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758536e7-587a-4590-a735-18086df37cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591ebb87-cb2d-4825-a268-ce05d2d0d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input : tensor output: binary string\n",
    "# def binary(num):\n",
    "#     return ''.join('{:0>8b}'.format(c) for c in struct.pack('!f', num))\n",
    "\n",
    "# #input: mantissa bitstring\n",
    "# #output: float value\n",
    "# def calc_mantissa(mantissa):\n",
    "#     res = 0\n",
    "#     for k in range(len(mantissa)):\n",
    "#         if mantissa[k] == '1':\n",
    "#           res += 2**(-k-1)\n",
    "#     return res\n",
    "\n",
    "# #input exp: bitstring\n",
    "# # new_exp_len: new length of exp\n",
    "# def calc_exp(exp, new_exp_len):\n",
    "#     limit = 2**(new_exp_len) - 1\n",
    "#     # if exp is more than new_exp_len limit, truncate to new_exp_len limit.\n",
    "#     bias = 2**(len(exp)-1) - 1\n",
    "#     val = int(exp,2) - bias\n",
    "#     if val > limit:\n",
    "#         return limit\n",
    "#     if val < -limit + 1:\n",
    "#         return -limit + 1\n",
    "\n",
    "#     return val\n",
    "\n",
    "# def round_fp8(x, exp = 4):\n",
    "#   '''\n",
    "#   Quantizes input tensor to FP8 data format\n",
    "#   inputs  x:      original tensor\n",
    "#           exp:    number of bits used for exponent field\n",
    "#                   e.g. E5M2 has 5 exp bits, E4M3 has 4 exp bits\n",
    "#   output  x_32:   quantized tensor\n",
    "#   '''\n",
    "\n",
    "#   x_fp8 = x.clone().to(torch.float32)\n",
    "\n",
    "#   for i in range(len(x_fp8)):\n",
    "#     for j in range(len(x_fp8[i])):\n",
    "#       result = 1.0\n",
    "#       bin_str = binary(x[i][j])\n",
    "\n",
    "#       bin_mantissa = bin_str[9:32]\n",
    "#       res_mantissa = bin_mantissa[:7-exp]    \n",
    "#       result += calc_mantissa(res_mantissa)\n",
    "\n",
    "#       bin_exp = bin_str[1:9]\n",
    "#       exp_int = calc_exp(bin_exp, exp)\n",
    "#       result *= 2**exp_int\n",
    "\n",
    "#       if bin_str[0] == '1':\n",
    "#         result *= -1\n",
    "\n",
    "#       x_fp8[i][j] = result    \n",
    "\n",
    "#   return x_fp8.to(torch.float32)\n",
    "\n",
    "# def dt_dequantize(quantized):\n",
    "#     \"\"\"\n",
    "#     Custom dequantization function.\n",
    "#     Assumes quantized values are in the custom format.\n",
    "#     \"\"\"\n",
    "#     dequantized = torch.zeros_like(quantized, dtype=torch.int32)\n",
    "\n",
    "#     for i, qval in enumerate(quantized.view(-1)):\n",
    "#         # Extract the bits\n",
    "#         sign_bit = (qval >> 7) & 1\n",
    "#         exp_bits = (qval >> 3) & 0xF\n",
    "#         bis_flag = (qval >> 2) & 1\n",
    "#         bis_tree = qval & 0x3\n",
    "\n",
    "#         # Compute the base value from the bisection tree bits\n",
    "#         base_value = bis_tree / 4.0\n",
    "\n",
    "#         # If bisection flag is set, adjust the base value\n",
    "#         if bis_flag:\n",
    "#             base_value += 0.5 / 4.0\n",
    "\n",
    "#         # Compute the dequantized value using the exponent\n",
    "#         value = base_value * (10 ** -exp_bits)\n",
    "\n",
    "\n",
    "# #the input is normalized tensor x,\n",
    "# def round_dt8(x, exp = 4):\n",
    "#     x_dt8 = x.clone().to(torch.float32)\n",
    "#     # print(f'DT quantizaiton; cloned shape: {x_dt8.shape}')\n",
    "#     for i, row in enumerate(x_dt8):\n",
    "#         # print(f'Iterating over rows: {x_dt8.shape}')\n",
    "#         for j, val in enumerate(row):\n",
    "#             # Determine sign bit\n",
    "#             sign_bit = 0 if val >= 0 else 1\n",
    "\n",
    "#             # Absolute value for further processing\n",
    "#             abs_val = abs(val)\n",
    "#                     # Determine the exponent bits (4 bits)\n",
    "#             exp_bits = 0\n",
    "#             for k in range(15):\n",
    "#                 if abs_val < 10**-k:\n",
    "#                     exp_bits = k - 1\n",
    "#                     break\n",
    "\n",
    "#             # Determine the bisection tree flag and binary bisection tree bits (3 bits)\n",
    "#             bis_flag = 1 if abs_val % (10**-exp_bits) != 0 else 0\n",
    "#             bis_tree = int((abs_val / (10**-exp_bits)) * 4) % 4\n",
    "\n",
    "#             # Combine the bits\n",
    "#             row[j] = (sign_bit << 7) | (exp_bits << 3) | (bis_flag << 2) | bis_tree\n",
    "#             # row[j] = dt_dequantize(row[j])\n",
    "\n",
    "#     return x_dt8\n",
    "\n",
    "# def quantize_rowwise(x: torch.Tensor, dt = False):\n",
    "#     abso = torch.abs(x)\n",
    "#     output_maxs  = torch.max(abso,1)[0].unsqueeze(-1)\n",
    "#     output = x[0]  / output_maxs[0,None] # What is this doing? Why x[0]?\n",
    "#     if not dt:\n",
    "#         output = round_fp8(output)\n",
    "#     else:\n",
    "#         output = round_dt8(output)\n",
    "#     return output, output_maxs\n",
    "\n",
    "# def dequantize_rowwise(x: torch.Tensor, state_x: torch.Tensor):\n",
    "#     output = x * state_x\n",
    "#     return output\n",
    "\n",
    "# def init_weights(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         init.normal_(m.weight, mean=0.0, std=1.0)\n",
    "#         if m.bias is not None:\n",
    "#             init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9bbcd5-9d72-478a-a992-923231fe51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import struct\n",
    "import torch.nn.init as init\n",
    "\n",
    "# input : tensor output: binary string\n",
    "def binary(num):\n",
    "  return ''.join('{:0>8b}'.format(c) for c in struct.pack('!f', num))\n",
    "\n",
    "#input: mantissa bitstring\n",
    "#output: float value\n",
    "def calc_mantissa(mantissa):\n",
    "  res = 0\n",
    "  for k in range(len(mantissa)):\n",
    "      if mantissa[k] == '1':\n",
    "        res += 2**(-k-1)\n",
    "  return res\n",
    "\n",
    "#input exp: bitstring\n",
    "# new_exp_len: new length of exp\n",
    "def calc_exp(exp, new_exp_len):\n",
    "  limit = 2**(new_exp_len) - 1\n",
    "  # if exp is more than new_exp_len limit, truncate to new_exp_len limit.\n",
    "  bias = 2**(len(exp)-1) - 1\n",
    "  val = int(exp,2) - bias\n",
    "  if val > limit:\n",
    "      return limit\n",
    "  if val < -limit + 1:\n",
    "      return -limit + 1\n",
    "      pass\n",
    "  return val\n",
    "\n",
    "\n",
    "def round_fp8(x, exp = 4):\n",
    "  '''\n",
    "  Quantizes input tensor to FP8 data format\n",
    "  inputs  x:      original tensor\n",
    "          exp:    number of bits used for exponent field\n",
    "                  e.g. E5M2 has 5 exp bits, E4M3 has 4 exp bits\n",
    "  output  x_32:   quantized tensor\n",
    "  '''\n",
    "\n",
    "  x_fp8 = copy.deepcopy(x)\n",
    "\n",
    "\n",
    "  result = 1.0\n",
    "  bin_str = binary(x)\n",
    "\n",
    "  bin_mantissa = bin_str[9:32]\n",
    "  res_mantissa = bin_mantissa[:7-exp]\n",
    "  result += calc_mantissa(res_mantissa)\n",
    "\n",
    "  bin_exp = bin_str[1:9]\n",
    "  exp_int = calc_exp(bin_exp, exp)\n",
    "  result *= 2**exp_int\n",
    "\n",
    "  if bin_str[0] == '1':\n",
    "    result *= -1\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def bisection_quantization(num, bits = 7):\n",
    "  val = abs(num)\n",
    "  inversed_bits = []\n",
    "  # Bisection tree quantization\n",
    "  range_min, range_max = 0, 1\n",
    "  for _ in range(bits):\n",
    "      mid = (range_min + range_max) / 2\n",
    "      if val >= mid:\n",
    "          inversed_bits.append(1)\n",
    "          range_min = mid\n",
    "      else:\n",
    "          inversed_bits.append(0)\n",
    "          range_max = mid\n",
    "\n",
    "  quantized_val = 0\n",
    "  for k, bit in enumerate(inversed_bits):\n",
    "      if bit:\n",
    "          quantized_val += 2**-(k + 1)\n",
    "\n",
    "  return quantized_val\n",
    "\n",
    "#the input is normalized tensor x,\n",
    "def round_dt8(x, exp = 4):\n",
    "  val = copy.deepcopy(x)\n",
    "  num_levels = 2 ** (7)\n",
    "\n",
    "\n",
    "  sign_bit = 0 if val >= 0 else 1\n",
    "  val = abs(val)\n",
    "  exp_bits = 0\n",
    "  while val < 0.1:\n",
    "      val *= 10\n",
    "      exp_bits += 1\n",
    "\n",
    "  bs_bits = max(0, 6 - exp_bits)\n",
    "  exp_bits = min(7, exp_bits)\n",
    "\n",
    "  if exp_bits == 0:\n",
    "      quantized_val = bisection_quantization(val, 7)\n",
    "  elif exp_bits >= 6:\n",
    "      quantized_val = val\n",
    "  else:\n",
    "      quantized_val = bisection_quantization(val, bs_bits)\n",
    "\n",
    "  quantized_val = quantized_val if sign_bit == 0 else -quantized_val\n",
    "  quantized_val *= 10**(-exp_bits)\n",
    "  return quantized_val\n",
    "\n",
    "\n",
    "def quantize_rowwise(x: torch.Tensor, dt = False):\n",
    "  abso = torch.abs(x)\n",
    "  output_maxs  = torch.max(abso,1)[0].unsqueeze(-1)\n",
    "  output = x  / output_maxs[None,:]\n",
    "  if not dt:\n",
    "      output.apply_(round_fp8)\n",
    "  else:\n",
    "      output.apply_(round_dt8)\n",
    "  return torch.squeeze(output), output_maxs\n",
    "\n",
    "def dequantize_rowwise(x: torch.Tensor, state_x: torch.Tensor):\n",
    "  output = x * state_x\n",
    "  return output\n",
    "\n",
    "def init_weights(m, in_std = 1.0):\n",
    "  if isinstance(m, nn.Linear):\n",
    "      init.normal_(m.weight, mean=0.0, std=in_std)\n",
    "      if m.bias is not None:\n",
    "          init.zeros_(m.bias)\n",
    "\n",
    "def measure_quantization_error(original_tensor, dequantized_tensor):\n",
    "  abs_error = torch.abs(original_tensor - dequantized_tensor)\n",
    "  return torch.mean(abs_error), abs_error\n",
    "\n",
    "def quantize_stable_embedding(x, batch_size, dt = False):\n",
    "  if (x.numel() % batch_size != 0):\n",
    "    print(\"Invalid batch size. Batch size should be a divisor of \" + str(x.numel()))\n",
    "    return \n",
    "\n",
    "  flatarg = torch.argsort(x.flatten())\n",
    "  indexing = flatarg.reshape((x.numel()//batch_size,batch_size))\n",
    "\n",
    "  reshapedx = x.flatten()[indexing]\n",
    "  output, maxes = quantize_rowwise(reshapedx,dt)\n",
    "\n",
    "  return output.reshape(x.shape), maxes, indexing\n",
    "\n",
    "def dequantize_stable_embedding(input, maxes, indexing):\n",
    "  outreshape = input.reshape(indexing.shape)\n",
    "\n",
    "  dequant = dequantize_rowwise(outreshape, maxes)\n",
    "  return dequant.reshape(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda97188-a7c4-4cf0-928a-2699bddcacf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76bad044-eff5-4297-bd72-9e375c3aba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_dequantize_dt(mat):\n",
    "    # return quantize_rowwise(mat, dt = True)[0]\n",
    "    testing_dt, dt_max = quantize_rowwise(mat, dt = True)\n",
    "    return dequantize_rowwise(testing_dt,dt_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708959f4-9672-48c7-a09e-e961b10eb8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1d6c027-60aa-42c8-9fc2-9d59c4a999b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "Layer 1 weights shape post-quantization: torch.Size([64, 3, 11, 11])\n",
      "Weights: tensor([[[[ 1.9580e-01,  1.5263e-01,  1.2334e-01,  ...,  5.0877e-02,\n",
      "            1.8501e-02,  4.7793e-02],\n",
      "          [ 1.3389e-01,  8.2233e-02,  6.8528e-02,  ...,  2.2140e-02,\n",
      "           -1.1386e-02,  6.7473e-03],\n",
      "          [ 1.0450e-01,  5.7597e-02,  4.7723e-02,  ...,  3.1267e-02,\n",
      "            3.9495e-03,  9.5447e-03],\n",
      "          ...,\n",
      "          [ 8.5936e-02,  1.0503e-01,  5.5699e-02,  ..., -2.0211e-01,\n",
      "           -1.3050e-01, -1.2095e-01],\n",
      "          [ 3.3525e-02,  6.7051e-02,  2.7938e-02,  ..., -2.0115e-01,\n",
      "           -1.1548e-01, -1.1920e-01],\n",
      "          [ 3.8063e-02,  6.7244e-02,  1.9031e-02,  ..., -1.2434e-01,\n",
      "           -1.0911e-01, -1.0911e-01]],\n",
      "\n",
      "         [[-8.0944e-02, -7.6126e-02, -1.2238e-01,  ...,  8.0944e-03,\n",
      "           -1.5418e-03,  5.9744e-02],\n",
      "          [-9.2535e-02, -9.5488e-02, -1.2502e-01,  ...,  1.4766e-02,\n",
      "            5.1189e-03,  5.8080e-02],\n",
      "          [-1.4660e-01, -1.3327e-01, -1.6926e-01,  ..., -4.7978e-03,\n",
      "            1.7325e-02,  5.8640e-02],\n",
      "          ...,\n",
      "          [-1.9580e-01, -1.0769e-01, -1.2238e-01,  ...,  3.8182e-01,\n",
      "            2.6434e-01,  1.6643e-01],\n",
      "          [-1.8060e-01, -8.8951e-02, -8.6256e-02,  ...,  2.8842e-01,\n",
      "            2.5607e-01,  1.8329e-01],\n",
      "          [-1.1851e-01, -4.5429e-02, -5.7281e-02,  ...,  2.4492e-01,\n",
      "            2.3307e-01,  1.7974e-01]],\n",
      "\n",
      "         [[-3.3490e-02, -2.6620e-02, -7.6426e-02,  ...,  1.8033e-02,\n",
      "           -1.7174e-02,  2.4903e-02],\n",
      "          [-2.2938e-02, -9.2438e-03, -4.3480e-02,  ...,  9.5862e-03,\n",
      "           -1.0956e-02,  2.6362e-02],\n",
      "          [-4.2805e-02, -2.2740e-02, -7.0897e-02,  ...,  2.1403e-03,\n",
      "            3.2104e-03,  1.8727e-02],\n",
      "          ...,\n",
      "          [-9.4530e-02, -2.7008e-02, -8.1025e-02,  ...,  1.5867e-01,\n",
      "            5.4017e-02, -2.4308e-02],\n",
      "          [-7.3066e-02, -2.7647e-03, -4.7394e-02,  ...,  4.0483e-02,\n",
      "            3.8508e-02, -1.6785e-02],\n",
      "          [-4.0466e-02,  1.2745e-02, -4.0147e-02,  ..., -7.0099e-03,\n",
      "            2.2304e-02, -7.3285e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3673e-02,  4.4467e-02,  1.0085e-01,  ...,  8.3376e-02,\n",
      "            4.6055e-02,  8.4170e-02],\n",
      "          [ 3.1601e-02,  3.4582e-02,  6.5587e-02,  ...,  6.4990e-02,\n",
      "            2.3850e-02,  7.5723e-02],\n",
      "          [ 3.7544e-02,  2.3950e-02,  5.5668e-02,  ..., -4.4017e-02,\n",
      "           -8.2208e-02,  5.5668e-02],\n",
      "          ...,\n",
      "          [ 2.6539e-02,  2.0581e-02,  3.7371e-02,  ..., -1.0291e-02,\n",
      "           -4.0621e-02,  6.8785e-02],\n",
      "          [ 4.1524e-02,  1.3530e-02,  3.3126e-02,  ..., -7.4650e-03,\n",
      "           -5.9254e-02,  5.5055e-02],\n",
      "          [-2.4018e-02, -2.9310e-02,  3.5824e-03,  ..., -3.9080e-02,\n",
      "           -5.1293e-02,  5.2921e-03]],\n",
      "\n",
      "         [[ 4.0572e-02,  3.3374e-02,  2.4212e-02,  ..., -3.4028e-03,\n",
      "           -3.5337e-02,  8.3107e-02],\n",
      "          [ 4.3038e-02,  5.5119e-02,  1.5856e-02,  ...,  2.7937e-02,\n",
      "           -3.9263e-02,  9.5893e-02],\n",
      "          [ 1.1253e-02,  7.9430e-04, -4.7989e-02,  ..., -1.6713e-01,\n",
      "           -2.1016e-01,  3.4751e-02],\n",
      "          ...,\n",
      "          [ 6.0081e-02,  6.7388e-02,  2.3545e-02,  ..., -1.6238e-02,\n",
      "           -6.6576e-02,  1.0311e-01],\n",
      "          [ 4.8922e-02,  4.4356e-02,  1.3046e-02,  ..., -2.2178e-02,\n",
      "           -8.0232e-02,  8.2841e-02],\n",
      "          [ 1.1329e-01,  1.1706e-01,  8.4021e-02,  ...,  4.0594e-02,\n",
      "           -7.9300e-03,  1.1989e-01]],\n",
      "\n",
      "         [[-3.3088e-02,  7.8209e-03, -3.0080e-02,  ..., -1.3837e-02,\n",
      "           -7.6404e-02,  4.7527e-02],\n",
      "          [-2.4266e-03,  5.7969e-02,  1.6177e-02,  ...,  7.2124e-02,\n",
      "           -4.8532e-03,  8.5605e-02],\n",
      "          [-9.7891e-02, -4.5081e-02, -9.2739e-02,  ..., -9.1451e-02,\n",
      "           -1.6358e-01,  3.8641e-02],\n",
      "          ...,\n",
      "          [-4.5014e-02,  1.9890e-02, -3.6640e-02,  ..., -4.3967e-02,\n",
      "           -1.3295e-01,  5.9670e-02],\n",
      "          [-6.0534e-02, -2.8052e-02, -8.1204e-02,  ..., -1.0040e-01,\n",
      "           -1.8751e-01,  7.0869e-03],\n",
      "          [ 2.0520e-02,  5.4422e-02, -3.5687e-03,  ..., -5.6206e-02,\n",
      "           -1.1330e-01,  4.9961e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6553e-02,  3.3777e-04,  1.5200e-02,  ...,  9.2886e-02,\n",
      "            1.0344e-01,  1.6888e-02],\n",
      "          [-1.3703e-01, -3.8463e-02, -3.8463e-02,  ...,  8.8946e-02,\n",
      "            4.0867e-02, -9.1350e-02],\n",
      "          [-1.8524e-01, -7.4979e-02, -5.7337e-02,  ...,  3.6608e-01,\n",
      "            2.0730e-01,  2.1171e-02],\n",
      "          ...,\n",
      "          [-2.7310e-01, -2.4045e-01, -3.7700e-01,  ...,  1.3655e-01,\n",
      "            2.2858e-01,  1.7217e-01],\n",
      "          [-2.6977e-01, -2.2672e-01, -3.6448e-01,  ...,  2.7551e-02,\n",
      "            1.1767e-01,  1.2628e-01],\n",
      "          [-1.9305e-01, -1.5097e-01, -3.0689e-01,  ..., -6.6823e-02,\n",
      "            3.9599e-03,  3.7124e-02]],\n",
      "\n",
      "         [[ 3.0735e-02, -1.6465e-02, -2.6345e-02,  ..., -4.8298e-02,\n",
      "            2.0856e-02,  1.1636e-01],\n",
      "          [ 7.3395e-02,  1.2385e-02, -4.5872e-03,  ..., -7.6836e-02,\n",
      "           -4.1285e-03,  1.0321e-01],\n",
      "          [ 9.5550e-02,  3.8220e-02,  6.7947e-03,  ..., -2.0809e-01,\n",
      "           -1.4226e-01,  2.0384e-03],\n",
      "          ...,\n",
      "          [ 2.0771e-01,  1.6617e-01,  2.1983e-01,  ..., -7.6162e-02,\n",
      "           -1.2117e-01, -9.5202e-02],\n",
      "          [ 2.1164e-01,  1.8166e-01,  2.2399e-01,  ..., -2.6455e-02,\n",
      "           -8.4657e-02, -4.5856e-02],\n",
      "          [ 1.4986e-01,  1.4831e-01,  1.7921e-01,  ...,  1.2359e-02,\n",
      "           -4.3257e-02, -3.2443e-02]],\n",
      "\n",
      "         [[ 3.3260e-02, -3.4646e-02, -6.6519e-03,  ..., -1.7184e-02,\n",
      "            7.2063e-03,  2.4945e-02],\n",
      "          [ 5.8293e-02, -8.4202e-03,  1.4249e-02,  ..., -2.5908e-02,\n",
      "            3.4004e-02,  8.4202e-02],\n",
      "          [ 1.2369e-01,  3.3368e-02,  4.8901e-02,  ..., -1.9560e-01,\n",
      "           -1.1794e-01,  3.4518e-02],\n",
      "          ...,\n",
      "          [ 1.7827e-01,  1.4086e-01,  2.7951e-01,  ..., -9.2438e-02,\n",
      "           -1.5626e-01, -1.4086e-01],\n",
      "          [ 2.0230e-01,  1.6818e-01,  3.0954e-01,  ..., -2.9248e-03,\n",
      "           -7.0683e-02, -7.5557e-02],\n",
      "          [ 6.5409e-02,  4.5283e-02,  1.9790e-01,  ...,  4.5283e-02,\n",
      "           -1.0063e-02, -4.8638e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.5420e-02, -3.4333e-02, -3.4333e-02,  ..., -4.2917e-04,\n",
      "           -1.3590e-02, -3.7552e-02],\n",
      "          [-3.4783e-02, -9.0381e-03, -3.3688e-02,  ..., -1.4242e-03,\n",
      "           -7.1210e-03, -2.8210e-02],\n",
      "          [-3.9906e-02, -1.4381e-02, -4.5658e-02,  ..., -1.6897e-02,\n",
      "           -1.8695e-02, -3.9187e-02],\n",
      "          ...,\n",
      "          [ 1.1508e-01,  1.0209e-01,  1.4292e-01,  ...,  1.5220e-01,\n",
      "            8.1670e-02,  5.7540e-02],\n",
      "          [ 1.2250e-01,  8.3915e-02,  8.2950e-02,  ..., -8.2950e-02,\n",
      "           -9.5489e-02, -8.8738e-02],\n",
      "          [-1.3058e-01, -1.5106e-01, -2.1507e-01,  ..., -2.7651e-01,\n",
      "           -2.5347e-01, -2.4835e-01]],\n",
      "\n",
      "         [[-6.5425e-02, -4.5334e-02, -4.5334e-02,  ..., -1.8030e-02,\n",
      "           -2.3697e-02, -3.1940e-02],\n",
      "          [-3.6271e-02, -3.9037e-02, -2.3976e-02,  ..., -2.5205e-02,\n",
      "           -1.7213e-02, -2.7050e-02],\n",
      "          [-3.4175e-02, -2.3151e-02, -4.6669e-02,  ..., -1.3229e-02,\n",
      "           -1.3229e-02, -3.0133e-02],\n",
      "          ...,\n",
      "          [ 1.4560e-01,  1.1183e-01,  1.6459e-01,  ...,  1.5615e-01,\n",
      "            7.5963e-02,  7.3853e-02],\n",
      "          [ 1.6729e-01,  1.0802e-01,  1.0538e-01,  ..., -8.2988e-02,\n",
      "           -8.6940e-02, -7.9036e-02],\n",
      "          [-1.5199e-01, -1.7686e-01, -2.2936e-01,  ..., -3.0673e-01,\n",
      "           -2.7081e-01, -2.7910e-01]],\n",
      "\n",
      "         [[-6.2841e-02, -5.3934e-02, -4.1564e-02,  ..., -9.8962e-03,\n",
      "           -1.0391e-02, -1.8308e-02],\n",
      "          [-2.7980e-02, -3.1317e-02, -2.9007e-02,  ...,  1.4375e-03,\n",
      "           -1.8482e-03, -1.8996e-02],\n",
      "          [-3.0803e-02, -2.1101e-02, -2.6195e-02,  ...,  2.5225e-03,\n",
      "            1.6978e-02, -1.8918e-02],\n",
      "          ...,\n",
      "          [ 5.9770e-02,  1.5788e-02,  7.3302e-02,  ...,  7.6686e-02,\n",
      "            4.2854e-02,  3.7215e-02],\n",
      "          [ 1.0817e-01,  7.9612e-02,  1.0990e-01,  ..., -9.3457e-03,\n",
      "           -6.9227e-03, -2.1634e-02],\n",
      "          [-1.1855e-01, -1.0890e-01, -1.3647e-01,  ..., -1.3509e-01,\n",
      "           -1.1028e-01, -1.3647e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9948e-02,  1.1539e-01,  2.9984e-02,  ...,  4.2705e-02,\n",
      "            3.3619e-02,  9.3588e-02],\n",
      "          [ 1.1428e-01,  7.1085e-02,  5.1289e-02,  ...,  5.2189e-02,\n",
      "            4.0491e-02,  9.7179e-02],\n",
      "          [-4.2038e-02, -5.4747e-02, -8.7986e-02,  ..., -1.1145e-01,\n",
      "           -8.7008e-02, -5.2791e-02],\n",
      "          ...,\n",
      "          [-2.9963e-02, -3.6476e-02,  2.4318e-02,  ...,  6.9479e-03,\n",
      "           -4.6898e-03, -5.5149e-02],\n",
      "          [ 6.1360e-03, -1.5340e-02,  7.2155e-02,  ...,  9.0904e-03,\n",
      "            2.1022e-02, -2.5567e-02],\n",
      "          [-9.8045e-02, -9.6931e-02, -1.3370e-02,  ..., -8.2447e-02,\n",
      "           -7.1305e-02, -1.4150e-01]],\n",
      "\n",
      "         [[-3.9498e-02, -2.3406e-02, -1.5653e-01,  ..., -1.0533e-01,\n",
      "           -7.4607e-02,  1.2288e-02],\n",
      "          [ 2.4273e-02,  1.2983e-02, -4.7982e-02,  ...,  1.1290e-03,\n",
      "            4.9676e-03,  7.1691e-02],\n",
      "          [-1.7333e-01, -1.4829e-01, -2.2918e-01,  ..., -1.9451e-01,\n",
      "           -1.5985e-01, -1.4251e-01],\n",
      "          ...,\n",
      "          [ 4.7131e-02,  4.3120e-02,  1.1131e-01,  ...,  1.0529e-01,\n",
      "            1.1632e-01,  4.6128e-02],\n",
      "          [ 1.2883e-01,  1.1068e-01,  2.0504e-01,  ...,  1.9778e-01,\n",
      "            1.9959e-01,  1.3790e-01],\n",
      "          [-6.9258e-02, -4.7711e-02,  5.5406e-02,  ...,  4.5403e-02,\n",
      "            6.2332e-02, -4.6172e-02]],\n",
      "\n",
      "         [[-1.2486e-01, -9.3119e-02, -2.4761e-01,  ..., -1.6719e-01,\n",
      "           -1.5661e-01, -4.8676e-02],\n",
      "          [-3.9878e-03,  6.4418e-03, -7.9755e-02,  ..., -7.9755e-03,\n",
      "           -1.3037e-02,  6.5185e-02],\n",
      "          [-2.8801e-01, -2.2767e-01, -3.2916e-01,  ..., -2.9624e-01,\n",
      "           -2.6058e-01, -2.3041e-01],\n",
      "          ...,\n",
      "          [ 1.1218e-01,  8.9463e-02,  1.7609e-01,  ...,  1.6189e-01,\n",
      "            1.7893e-01,  9.7984e-02],\n",
      "          [ 2.1104e-01,  1.9020e-01,  2.9963e-01,  ...,  2.9702e-01,\n",
      "            3.0223e-01,  2.3189e-01],\n",
      "          [ 1.0828e-02,  5.7327e-03,  1.4650e-01,  ...,  1.6880e-01,\n",
      "            2.0064e-01,  5.8920e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.0519e-02,  6.1047e-02,  1.3367e-01,  ..., -1.6841e-02,\n",
      "            7.1573e-03, -5.8942e-03],\n",
      "          [ 6.6746e-02,  1.3119e-01, -1.2659e-01,  ...,  7.5952e-02,\n",
      "           -1.3809e-02, -2.4167e-02],\n",
      "          [ 1.1226e-01, -1.2611e-01, -1.9531e-01,  ..., -5.2288e-02,\n",
      "           -8.6121e-02,  3.5371e-02],\n",
      "          ...,\n",
      "          [-1.7183e-01,  2.5965e-02,  3.3602e-01,  ...,  2.6347e-01,\n",
      "            9.1642e-02, -1.7565e-01],\n",
      "          [ 7.8027e-02,  1.4630e-01,  6.5022e-03,  ..., -8.7780e-02,\n",
      "           -2.6009e-01, -8.7780e-02],\n",
      "          [ 1.3848e-02, -6.2747e-02, -9.9529e-02,  ..., -1.2117e-01,\n",
      "            7.1401e-02,  8.8711e-02]],\n",
      "\n",
      "         [[-8.3085e-02,  7.6400e-02,  1.2128e-01,  ..., -1.0314e-02,\n",
      "            1.9100e-02, -1.5280e-04],\n",
      "          [ 9.9469e-02,  1.1794e-01, -1.4494e-01,  ...,  1.1084e-01,\n",
      "            1.3073e-02, -1.8473e-02],\n",
      "          [ 1.3530e-01, -1.4694e-01, -1.7458e-01,  ..., -5.6740e-02,\n",
      "           -9.0202e-02,  5.0920e-02],\n",
      "          ...,\n",
      "          [-1.5954e-01,  8.5088e-02,  4.8926e-01,  ...,  3.1376e-01,\n",
      "            1.5954e-01, -1.3295e-01],\n",
      "          [ 1.3385e-01,  2.2564e-01,  5.7366e-02,  ..., -6.1191e-03,\n",
      "           -2.2947e-01, -6.8840e-02],\n",
      "          [ 3.5734e-02, -7.3454e-02, -1.5088e-01,  ..., -8.1395e-02,\n",
      "            7.5439e-02,  1.1713e-01]],\n",
      "\n",
      "         [[-1.0926e-01,  5.0927e-02,  1.1760e-01,  ..., -4.4446e-02,\n",
      "            5.1853e-03, -7.7780e-03],\n",
      "          [ 5.4547e-02,  1.0341e-01, -1.4432e-01,  ...,  1.0000e-01,\n",
      "            1.1364e-02, -6.3638e-03],\n",
      "          [ 1.0610e-01, -1.0474e-01, -1.7276e-01,  ..., -4.4890e-02,\n",
      "           -8.9781e-02,  4.7611e-02],\n",
      "          ...,\n",
      "          [-1.7630e-01,  5.4569e-02,  3.8618e-01,  ...,  2.3927e-01,\n",
      "            9.6546e-02, -1.2593e-01],\n",
      "          [ 8.6654e-02,  1.8615e-01,  4.1722e-02,  ..., -5.1351e-02,\n",
      "           -2.1824e-01, -4.1722e-02],\n",
      "          [ 4.0585e-02, -7.4926e-02, -1.4361e-01,  ..., -5.4633e-02,\n",
      "            9.3657e-02,  8.7413e-02]]]])\n",
      "Layer 4\n",
      "Layer 4 weights shape post-quantization: torch.Size([192, 64, 5, 5])\n",
      "Weights: tensor([[[[ 7.0181e-03,  1.8247e-03,  4.4565e-02, -3.0880e-02,  1.8247e-03],\n",
      "          [ 2.5419e-02, -8.5277e-03,  1.0414e-01, -8.8557e-02,  8.5277e-03],\n",
      "          [ 1.8246e-02, -1.1034e-01,  2.1721e-02, -8.1671e-02,  2.0852e-02],\n",
      "          [-1.6049e-02, -5.6617e-02, -4.8593e-02,  1.2483e-02, -1.8278e-02],\n",
      "          [-2.7123e-02, -7.4973e-03,  2.8005e-02,  7.2768e-03, -1.4554e-02]],\n",
      "\n",
      "         [[-2.0311e-03, -1.9949e-02, -4.6063e-02, -5.8033e-03, -5.4405e-03],\n",
      "          [-1.5898e-02,  1.4271e-02, -6.0089e-03, -1.2143e-02, -8.2622e-03],\n",
      "          [-3.2610e-02,  4.7062e-02, -2.0752e-04, -1.8158e-02,  7.7818e-03],\n",
      "          [-5.4963e-02, -1.2118e-02,  1.4282e-02, -1.9908e-02, -4.8471e-04],\n",
      "          [-2.2680e-03, -4.0005e-02, -1.6065e-02, -1.8270e-02,  1.3860e-02]],\n",
      "\n",
      "         [[-1.8125e-02, -7.1712e-02, -1.0008e-01,  3.4674e-02,  6.0680e-02],\n",
      "          [-1.7939e-02, -1.1991e-01, -2.8324e-02,  4.9095e-02,  5.1928e-02],\n",
      "          [-1.4243e-02,  3.7226e-02,  2.0555e-01,  4.0464e-02, -5.5030e-02],\n",
      "          [ 2.2080e-02,  1.1150e-01,  2.6496e-02, -1.4021e-01, -4.0848e-02],\n",
      "          [ 5.1494e-02,  6.4368e-02,  6.7755e-03, -8.6049e-02, -5.9625e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3170e-02,  1.5880e-02,  3.3062e-02, -2.2128e-02, -8.8513e-03],\n",
      "          [-2.1988e-02,  1.5392e-02,  9.3082e-02, -5.1305e-02, -5.7902e-02],\n",
      "          [-4.9923e-02, -8.7557e-02,  9.7541e-02, -5.5299e-03, -7.5268e-02],\n",
      "          [ 6.6634e-03,  2.9729e-02,  6.5096e-02,  5.3307e-02, -1.8452e-02],\n",
      "          [-9.0257e-03,  6.4130e-03, -3.0165e-02, -1.4726e-02, -2.1139e-02]],\n",
      "\n",
      "         [[-3.0003e-02, -4.6419e-02,  5.2646e-02,  1.3586e-02, -7.1893e-02],\n",
      "          [-3.4506e-02, -5.9468e-02,  9.3240e-02,  3.8177e-02,  2.2025e-02],\n",
      "          [ 4.4083e-03, -1.3776e-02, -7.6456e-02, -8.7477e-02, -8.9543e-03],\n",
      "          [-3.0335e-02,  7.4017e-02,  7.7050e-02,  1.6987e-02, -4.4289e-02],\n",
      "          [-6.7651e-02, -2.5172e-03,  9.9903e-02,  2.5172e-02, -8.2597e-02]],\n",
      "\n",
      "         [[-1.9284e-03,  1.2397e-02, -4.2700e-02, -8.7466e-02,  3.9945e-02],\n",
      "          [ 3.0403e-02,  1.5202e-02,  1.3808e-01, -1.6088e-01, -1.1528e-01],\n",
      "          [ 6.8464e-03, -1.3693e-01,  2.4153e-01,  1.8828e-01, -1.4834e-01],\n",
      "          [ 2.5601e-02, -7.7871e-02, -1.3547e-01,  1.1947e-01,  2.6668e-02],\n",
      "          [ 4.5053e-02,  7.5286e-02, -4.1496e-02,  2.8454e-03,  1.8377e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6408e-03, -5.0809e-02,  2.3204e-02, -2.2804e-02, -1.0402e-02],\n",
      "          [ 1.9564e-02, -7.0836e-02, -8.0955e-02, -8.5678e-02, -2.4961e-02],\n",
      "          [-6.5355e-03, -5.2647e-02, -2.3056e-01, -6.3540e-02, -4.7201e-02],\n",
      "          [-5.1492e-02,  2.4186e-02, -9.9083e-02, -1.9505e-02, -1.9505e-02],\n",
      "          [-1.1060e-02,  5.6878e-03, -6.6884e-02, -2.0539e-02, -1.9486e-02]],\n",
      "\n",
      "         [[ 4.4090e-02,  4.0170e-02, -6.2215e-02,  1.4697e-02, -3.8211e-02],\n",
      "          [ 2.4541e-02,  6.4553e-02, -6.7754e-02, -2.5074e-02, -5.1749e-02],\n",
      "          [-3.6467e-02,  4.8242e-02, -7.9771e-03, -2.2792e-02,  5.3181e-03],\n",
      "          [-2.9502e-02, -7.0694e-02, -1.9483e-02, -1.2246e-02, -3.7295e-02],\n",
      "          [-2.1744e-02, -1.0621e-01,  1.2545e-02,  2.5090e-02, -1.4217e-02]],\n",
      "\n",
      "         [[-1.3247e-02,  1.6823e-01,  5.6961e-02, -1.8545e-02, -5.2987e-03],\n",
      "          [-9.8329e-02,  2.0149e-01,  2.0472e-01,  1.7409e-02,  1.3540e-02],\n",
      "          [-1.1402e-01,  1.1402e-01,  3.8106e-01,  6.0009e-02,  4.5007e-02],\n",
      "          [-4.1473e-02, -8.8871e-02,  2.5081e-01,  9.8746e-02, -2.3699e-03],\n",
      "          [-2.1467e-02, -1.9473e-01,  1.0733e-01,  1.5487e-01,  3.2200e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6322e-03,  2.5944e-03,  4.2159e-03, -2.5296e-02, -4.1186e-02],\n",
      "          [-3.0106e-03,  3.1988e-02,  6.5857e-03,  2.6343e-02, -3.9828e-02],\n",
      "          [-9.5301e-03,  6.0516e-02, -2.2872e-03,  3.0020e-02,  7.6241e-04],\n",
      "          [-4.0931e-02,  4.5433e-02,  5.1982e-02, -1.4735e-02, -6.9582e-03],\n",
      "          [-5.2532e-02, -3.4332e-02,  2.7714e-02, -2.8127e-02, -3.3091e-02]],\n",
      "\n",
      "         [[ 8.8459e-02,  4.5274e-02, -6.3384e-02,  2.4378e-02, -8.3583e-04],\n",
      "          [ 4.0260e-02,  5.7874e-02, -7.9891e-02,  2.8308e-02,  2.8308e-02],\n",
      "          [-6.8682e-02, -4.4290e-02, -5.9696e-02, -8.1520e-02, -1.7331e-02],\n",
      "          [-1.5183e-01, -5.7386e-02,  1.9129e-02, -6.5755e-02, -9.8034e-02],\n",
      "          [-8.1967e-02, -2.5816e-02,  1.6781e-02, -3.7434e-02, -5.4860e-02]],\n",
      "\n",
      "         [[ 1.2747e-03,  2.2762e-03,  1.4454e-02, -1.5933e-03, -1.3657e-04],\n",
      "          [-7.5758e-03,  3.5634e-02, -2.7778e-02,  1.6554e-02, -4.4894e-04],\n",
      "          [-6.7346e-03,  7.6365e-02, -3.0666e-02,  5.2914e-02,  2.7058e-02],\n",
      "          [-2.0776e-02,  3.9381e-02,  3.1008e-02,  4.9614e-03, -2.4807e-03],\n",
      "          [ 4.6240e-04,  2.3120e-02,  4.8938e-02, -2.6974e-02, -7.3214e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1475e-02, -5.3931e-02, -7.2864e-02, -3.7866e-02,  5.5078e-03],\n",
      "          [ 1.5515e-01, -7.6964e-02, -7.2078e-02, -4.6423e-02,  5.3753e-03],\n",
      "          [ 2.3118e-02, -4.3822e-02, -4.3476e-02, -1.4147e-02,  1.7253e-02],\n",
      "          [ 1.5848e-02,  1.2984e-02, -1.5275e-02, -2.1194e-02, -2.4249e-02],\n",
      "          [ 4.9286e-02,  1.5523e-02,  1.3583e-02,  4.0360e-03, -3.5315e-02]],\n",
      "\n",
      "         [[ 5.0145e-02, -2.2111e-02, -3.0403e-02, -2.8034e-02, -4.8961e-03],\n",
      "          [ 7.6921e-02, -8.3496e-02, -7.6921e-02, -7.2319e-02, -4.4706e-03],\n",
      "          [ 8.3509e-02, -7.0815e-02, -8.4845e-02, -7.5492e-02, -1.9374e-02],\n",
      "          [ 6.9937e-02, -5.0738e-02, -8.7078e-02, -5.9652e-02, -1.6456e-02],\n",
      "          [ 8.8398e-02,  1.5313e-02, -2.1578e-02, -2.0185e-02,  1.7401e-02]],\n",
      "\n",
      "         [[ 5.8602e-03, -1.0795e-02, -3.6703e-02, -2.9609e-02, -3.9171e-02],\n",
      "          [ 1.9623e-01,  3.0903e-03, -3.0903e-02, -2.9357e-02, -3.2448e-02],\n",
      "          [ 1.1025e-01, -5.2087e-03, -4.9483e-02, -2.7780e-02, -1.3022e-02],\n",
      "          [-4.8459e-02, -1.7552e-02, -3.0144e-02, -3.0526e-03,  4.9604e-03],\n",
      "          [-3.7417e-02,  1.2963e-03, -1.7677e-03, -1.6204e-02, -2.1213e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6321e-02, -7.4333e-03, -1.8098e-02, -2.0522e-02, -1.0988e-03],\n",
      "          [ 1.6766e-01,  1.8483e-02, -1.1618e-02, -1.0033e-02, -1.0561e-02],\n",
      "          [ 6.9090e-02, -1.3056e-02, -3.9169e-02, -1.0880e-02,  4.3521e-03],\n",
      "          [ 1.4364e-02, -9.6135e-03, -1.1762e-04, -2.9406e-03,  2.9406e-03],\n",
      "          [ 2.7924e-02, -3.5180e-04,  9.0150e-03,  1.2093e-02,  3.0783e-03]],\n",
      "\n",
      "         [[ 2.0059e-02, -2.8781e-02, -3.6920e-02, -2.7327e-02, -1.9768e-03],\n",
      "          [ 2.0578e-01, -1.0532e-01, -6.3191e-02,  1.9443e-03,  1.1666e-03],\n",
      "          [ 2.9857e-02, -1.1490e-01, -1.0133e-01, -2.0809e-02,  1.0857e-02],\n",
      "          [ 6.7729e-03, -3.9098e-02, -3.9098e-02, -1.3854e-02,  2.8939e-02],\n",
      "          [-2.1107e-02, -5.6284e-02, -8.1228e-02, -3.1340e-02, -1.0233e-02]],\n",
      "\n",
      "         [[-2.2685e-02,  5.1801e-03,  6.7877e-03, -2.0720e-02, -1.0896e-02],\n",
      "          [ 6.2458e-02, -3.0983e-02,  5.3114e-03,  1.2787e-02, -7.3769e-03],\n",
      "          [ 1.1013e-02, -5.5945e-02, -9.2507e-03,  1.5858e-03, -1.7180e-02],\n",
      "          [-1.4958e-02,  4.7236e-03, -2.4996e-02, -1.2793e-02, -1.0038e-02],\n",
      "          [ 1.0735e-02,  1.0735e-02, -1.8676e-02, -7.7938e-03,  3.0881e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.8435e-02,  1.8418e-02,  4.1037e-02, -6.7856e-03, -3.7805e-02],\n",
      "          [-1.8785e-02, -4.2366e-02, -2.3981e-03, -3.2773e-02, -5.0759e-02],\n",
      "          [-3.7576e-02, -5.1420e-02, -6.2792e-02, -5.9331e-02, -3.4115e-02],\n",
      "          [-4.4741e-06, -1.0719e-02, -4.1013e-02, -5.9189e-02, -2.3303e-02],\n",
      "          [ 1.4966e-02, -2.4451e-03,  1.4334e-03, -2.6770e-02, -1.6020e-02]],\n",
      "\n",
      "         [[-4.5959e-03,  4.2424e-03, -4.1717e-02, -4.4898e-02, -1.6616e-02],\n",
      "          [-2.8970e-02,  4.0466e-03,  9.1969e-04,  5.8400e-02,  3.7247e-02],\n",
      "          [-2.4986e-02,  4.3725e-03, -3.9040e-02, -2.8109e-02, -6.6108e-02],\n",
      "          [-3.4957e-03,  2.2184e-02, -3.4957e-02, -8.2013e-02, -8.5375e-02],\n",
      "          [-4.6902e-03,  4.4738e-02,  1.4792e-02, -3.4996e-02, -4.5820e-02]],\n",
      "\n",
      "         [[-4.5987e-02, -5.7984e-02, -1.2696e-01, -4.7986e-02,  7.7978e-02],\n",
      "          [-4.0335e-02, -4.8978e-02, -6.2423e-02,  3.3612e-02,  1.2197e-01],\n",
      "          [ 3.2197e-02,  3.6588e-02,  6.1955e-02,  3.6588e-02, -3.5124e-03],\n",
      "          [ 3.6175e-02,  3.9001e-02,  7.1785e-02,  1.0174e-02, -5.7654e-02],\n",
      "          [ 7.0427e-03,  2.5152e-02,  6.3887e-02,  5.2820e-02, -1.1067e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8802e-02, -3.2680e-02, -3.4471e-02,  5.6855e-02,  1.4326e-02],\n",
      "          [-6.0115e-02, -6.9406e-02, -5.8476e-02,  6.6673e-02,  3.3337e-02],\n",
      "          [ 2.5888e-02,  1.8452e-02, -3.4977e-02,  1.3770e-02,  3.0846e-02],\n",
      "          [ 1.3033e-02,  1.2521e-02, -2.1976e-02, -2.4021e-02,  3.2453e-02],\n",
      "          [-1.0509e-02,  8.4533e-03,  2.7416e-04, -2.9015e-02, -5.7117e-03]],\n",
      "\n",
      "         [[-6.8487e-02, -7.5498e-03, -4.9613e-03, -2.7503e-02, -4.3142e-03],\n",
      "          [-6.9327e-02, -3.2273e-02, -6.0960e-02, -1.5180e-01, -8.0084e-02],\n",
      "          [-9.7372e-02, -2.4668e-02, -1.8176e-02,  6.8810e-02,  1.6488e-01],\n",
      "          [-3.0772e-02, -3.4045e-02, -5.4342e-02,  3.6664e-02,  8.3149e-02],\n",
      "          [-5.9092e-02, -2.3730e-02, -4.9786e-02,  3.1175e-02,  2.2799e-02]],\n",
      "\n",
      "         [[ 4.1929e-02,  2.6514e-02, -3.0214e-02,  2.7131e-03, -7.8309e-02],\n",
      "          [ 6.6161e-02,  3.9261e-02, -6.3253e-02,  1.3087e-02,  9.2335e-02],\n",
      "          [ 4.8477e-02,  3.0849e-02, -7.4919e-02, -1.1194e-01, -3.1730e-02],\n",
      "          [ 3.8028e-02,  5.7042e-02,  5.7570e-02, -4.8591e-03, -6.7077e-02],\n",
      "          [-2.3759e-03,  2.7059e-02,  4.1908e-02,  2.5739e-02, -1.1880e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9358e-02, -1.2086e-02,  1.5185e-02, -2.1073e-02, -3.4399e-02],\n",
      "          [ 3.0817e-03, -4.4514e-02, -7.9611e-02, -1.0872e-01, -7.9611e-02],\n",
      "          [-1.7650e-02, -2.4514e-02, -9.9037e-02, -1.2453e-01, -8.0406e-02],\n",
      "          [ 3.7543e-03, -1.1856e-02, -6.0266e-02, -6.2736e-02, -5.0881e-02],\n",
      "          [ 2.4958e-02, -2.6289e-02, -4.2261e-02, -7.9864e-03, -2.8285e-02]],\n",
      "\n",
      "         [[ 7.8810e-02,  1.0294e-02, -2.0426e-01, -1.2384e-01, -3.2167e-02],\n",
      "          [ 1.2981e-01,  1.2470e-01, -7.9729e-02, -1.1857e-01, -1.1550e-01],\n",
      "          [ 1.7129e-01,  2.0661e-01,  4.0616e-02, -8.6530e-02, -2.2427e-01],\n",
      "          [ 7.2156e-02,  1.4182e-01,  9.0817e-02,  3.9810e-03, -1.5800e-01],\n",
      "          [ 4.6264e-02,  1.0409e-01,  1.3353e-01,  7.9910e-02, -8.0961e-02]],\n",
      "\n",
      "         [[-6.8814e-02, -4.9850e-02, -6.0687e-02, -2.8718e-02,  6.8814e-02],\n",
      "          [-3.8354e-02, -3.6498e-02, -7.8564e-02, -4.4540e-02,  1.0516e-02],\n",
      "          [ 2.0248e-02,  3.0372e-02, -1.9404e-02, -1.0714e-01, -6.7493e-02],\n",
      "          [-4.6256e-02, -3.3984e-03,  1.4160e-02, -9.2513e-02, -1.1989e-01],\n",
      "          [-2.7005e-02, -1.7360e-02, -4.6294e-03, -8.7766e-02, -1.2249e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4123e-02, -2.8631e-02, -6.3124e-04,  2.3221e-02,  1.1047e-02],\n",
      "          [-6.7683e-03, -3.8354e-02, -5.7305e-02,  1.5793e-02,  3.9256e-02],\n",
      "          [-6.3083e-03, -4.7312e-02, -1.0014e-01,  4.7312e-03,  1.0014e-01],\n",
      "          [ 2.5291e-03,  1.3151e-02, -1.4669e-02, -2.1413e-02,  9.7790e-03],\n",
      "          [-1.3188e-02, -5.6172e-03, -5.2508e-03, -7.2046e-03,  1.5508e-02]],\n",
      "\n",
      "         [[-3.3098e-03, -1.1676e-01, -1.0389e-01, -1.9307e-02,  6.8034e-02],\n",
      "          [ 8.0024e-02, -2.9277e-02, -2.4788e-01, -1.1906e-01, -3.3181e-02],\n",
      "          [ 1.1953e-01,  7.6369e-02, -1.1787e-01, -2.1084e-01, -9.4631e-02],\n",
      "          [ 2.5946e-02,  3.9400e-02,  2.3063e-02, -9.8019e-02, -1.2204e-01],\n",
      "          [-2.9017e-04, -3.5666e-02,  1.8740e-02, -1.6926e-03, -7.6773e-02]],\n",
      "\n",
      "         [[ 3.3269e-03, -2.4841e-03,  9.0936e-03,  2.8168e-02,  1.0203e-02],\n",
      "          [ 4.9468e-03, -1.0600e-02, -1.0777e-02,  1.9787e-02,  2.2437e-02],\n",
      "          [ 3.1862e-02, -9.0317e-04, -1.8314e-02,  1.4049e-04,  2.9855e-02],\n",
      "          [ 2.4925e-02,  2.9584e-02, -1.6772e-03, -8.3859e-03,  1.2113e-02],\n",
      "          [ 8.9648e-03, -4.8559e-03,  2.1665e-03, -2.3719e-02, -1.9237e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4907e-03, -2.2047e-02, -2.3333e-02, -1.1023e-02,  7.3489e-04],\n",
      "          [-2.6463e-02, -4.0839e-02, -4.1492e-02, -2.9077e-02, -1.9602e-02],\n",
      "          [-1.4056e-02, -4.0547e-02, -6.8659e-02, -4.5412e-02, -2.2165e-02],\n",
      "          [-1.9289e-02, -4.7303e-02, -5.8325e-02, -2.4800e-02, -2.5718e-02],\n",
      "          [-1.2118e-02, -6.9454e-03, -1.8767e-02,  3.9899e-03,  4.1377e-03]],\n",
      "\n",
      "         [[ 9.9543e-03,  2.1529e-02,  1.7131e-02, -3.7039e-05,  2.9400e-02],\n",
      "          [-2.0310e-02, -2.8982e-02, -2.8982e-02, -1.8028e-02, -7.3025e-03],\n",
      "          [-4.0129e-02, -4.7630e-02, -6.0006e-03, -2.5502e-02, -1.5001e-03],\n",
      "          [-1.2153e-02, -2.3386e-02,  6.9975e-03, -2.0624e-03, -5.3402e-03],\n",
      "          [ 3.2171e-03,  1.0146e-02,  3.1429e-02,  8.6616e-03,  6.9292e-03]],\n",
      "\n",
      "         [[-1.0900e-02,  8.3849e-03,  3.5217e-03, -1.7273e-02,  2.1298e-02],\n",
      "          [-2.9168e-02, -1.1084e-02, -3.7043e-02, -2.9751e-02, -6.7086e-03],\n",
      "          [-1.4538e-02,  1.6153e-03, -7.9524e-03, -1.5781e-02,  2.2366e-03],\n",
      "          [ 5.1235e-03, -7.1974e-03, -1.5493e-02, -6.2214e-03,  5.6115e-03],\n",
      "          [ 8.4125e-03, -9.7407e-03,  1.0479e-02, -1.2988e-02, -1.8744e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.7916e-03, -3.4892e-02, -1.9232e-02, -2.1704e-02, -9.8905e-04],\n",
      "          [-5.6912e-02, -5.6449e-02, -4.7195e-02, -5.8763e-02, -3.8867e-02],\n",
      "          [ 2.2644e-02,  2.5999e-02,  3.5503e-02,  8.6662e-03,  2.3762e-02],\n",
      "          [ 1.1877e-02,  1.3856e-02,  5.0278e-02,  1.2273e-02,  1.7419e-02],\n",
      "          [-4.3873e-03, -8.3093e-03,  2.9249e-04,  6.3815e-03,  8.4422e-03]],\n",
      "\n",
      "         [[ 2.5183e-03,  1.4165e-02,  6.6630e-02,  1.2067e-02,  1.9936e-02],\n",
      "          [-1.1023e-02,  5.1314e-02,  1.2068e-01,  4.5612e-02,  1.3304e-02],\n",
      "          [-2.1109e-02,  1.0555e-02,  8.9362e-02,  1.7591e-02, -1.0555e-02],\n",
      "          [ 3.2017e-03,  1.3340e-03,  8.4712e-02, -1.0005e-02, -5.0027e-02],\n",
      "          [-4.0456e-02, -4.7198e-02, -5.7087e-02, -4.6749e-02, -3.4162e-02]],\n",
      "\n",
      "         [[ 7.0890e-02,  2.2886e-02, -7.8147e-03, -8.3729e-03, -5.3586e-03],\n",
      "          [ 3.2593e-02, -7.4875e-03, -5.5936e-02, -3.7878e-02, -1.9820e-02],\n",
      "          [-5.2608e-03, -4.1429e-02, -8.3515e-02, -5.3923e-02, -1.9070e-02],\n",
      "          [-3.5071e-03, -3.8906e-02, -6.9593e-02, -3.9454e-02,  1.7535e-03],\n",
      "          [ 5.1133e-02,  1.1676e-02, -1.8923e-02,  1.8118e-02,  2.4560e-02]]]])\n",
      "Layer 7\n",
      "Layer 7 weights shape post-quantization: torch.Size([384, 192, 3, 3])\n",
      "Weights: tensor([[[[ 0.0114,  0.0073,  0.0290],\n",
      "          [ 0.0414,  0.0520, -0.0201],\n",
      "          [ 0.0090,  0.0186, -0.0194]],\n",
      "\n",
      "         [[-0.0393, -0.1085, -0.0803],\n",
      "          [-0.0132, -0.0931, -0.0220],\n",
      "          [-0.0173, -0.0417,  0.0524]],\n",
      "\n",
      "         [[ 0.0177, -0.0330, -0.0270],\n",
      "          [ 0.0428, -0.0172,  0.0219],\n",
      "          [ 0.0054, -0.0341,  0.0009]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0223,  0.0483,  0.0808],\n",
      "          [-0.0523, -0.0301,  0.0256],\n",
      "          [-0.0191, -0.0657, -0.0341]],\n",
      "\n",
      "         [[-0.0009, -0.0475, -0.0710],\n",
      "          [-0.0237, -0.0023, -0.0039],\n",
      "          [-0.0359,  0.0799,  0.0541]],\n",
      "\n",
      "         [[ 0.0226, -0.0005, -0.0025],\n",
      "          [-0.0098, -0.0198, -0.0130],\n",
      "          [-0.0161, -0.0222,  0.0122]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0084, -0.0427,  0.0091],\n",
      "          [ 0.0621,  0.0357,  0.0171],\n",
      "          [-0.0221, -0.0132, -0.0221]],\n",
      "\n",
      "         [[-0.0305,  0.0139,  0.0190],\n",
      "          [-0.0080, -0.0021, -0.0243],\n",
      "          [ 0.0363, -0.0303, -0.0349]],\n",
      "\n",
      "         [[-0.0178, -0.0241, -0.0209],\n",
      "          [-0.0209, -0.0386, -0.0576],\n",
      "          [-0.0244, -0.0839, -0.0707]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0039,  0.0093, -0.0273],\n",
      "          [-0.0110,  0.1208,  0.0099],\n",
      "          [ 0.0262,  0.0536, -0.0072]],\n",
      "\n",
      "         [[ 0.0038, -0.0047,  0.0011],\n",
      "          [-0.0118,  0.0177,  0.0230],\n",
      "          [ 0.0203, -0.0127, -0.0225]],\n",
      "\n",
      "         [[ 0.0472,  0.0600,  0.0581],\n",
      "          [-0.0194, -0.0209, -0.0196],\n",
      "          [-0.0009, -0.0151, -0.0103]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0026,  0.0079, -0.0130],\n",
      "          [ 0.0218,  0.0478,  0.0406],\n",
      "          [-0.0014,  0.0729,  0.0120]],\n",
      "\n",
      "         [[-0.0122, -0.0456, -0.0111],\n",
      "          [-0.0494,  0.0250,  0.0634],\n",
      "          [-0.0465, -0.0414, -0.0077]],\n",
      "\n",
      "         [[-0.0368, -0.0128,  0.0218],\n",
      "          [ 0.0283,  0.0148, -0.0571],\n",
      "          [-0.0235, -0.0050,  0.0078]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0026, -0.0240, -0.0045],\n",
      "          [ 0.0082, -0.0018,  0.0107],\n",
      "          [-0.0234,  0.0118,  0.0306]],\n",
      "\n",
      "         [[-0.0254, -0.0214,  0.0224],\n",
      "          [-0.0491, -0.0050,  0.0799],\n",
      "          [-0.0176, -0.0328,  0.0240]],\n",
      "\n",
      "         [[-0.0045,  0.0198,  0.0156],\n",
      "          [ 0.0117,  0.0067, -0.0002],\n",
      "          [ 0.0027, -0.0013, -0.0083]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0147,  0.0416,  0.0043],\n",
      "          [-0.0269, -0.0150,  0.0186],\n",
      "          [-0.0148, -0.0460,  0.0019]],\n",
      "\n",
      "         [[ 0.0071, -0.0038, -0.0347],\n",
      "          [ 0.0408,  0.0231, -0.0524],\n",
      "          [-0.0310, -0.0328, -0.0044]],\n",
      "\n",
      "         [[ 0.0305,  0.0450,  0.0333],\n",
      "          [ 0.0339,  0.0406,  0.0281],\n",
      "          [ 0.0265,  0.0060, -0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0153,  0.0138,  0.0255],\n",
      "          [ 0.0488, -0.0513,  0.0052],\n",
      "          [-0.0440, -0.0443,  0.0373]],\n",
      "\n",
      "         [[-0.0005,  0.0020, -0.0480],\n",
      "          [-0.0086,  0.0146, -0.0545],\n",
      "          [ 0.0255, -0.0219, -0.0514]],\n",
      "\n",
      "         [[-0.0175, -0.0147, -0.0095],\n",
      "          [-0.0221,  0.0033, -0.0044],\n",
      "          [-0.0068,  0.0209,  0.0268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0206,  0.0428, -0.0105],\n",
      "          [ 0.0295, -0.0341, -0.0446],\n",
      "          [ 0.0632,  0.0318,  0.0477]],\n",
      "\n",
      "         [[ 0.0449, -0.0417, -0.0007],\n",
      "          [-0.0006,  0.0418, -0.0453],\n",
      "          [-0.0272,  0.0436, -0.0272]],\n",
      "\n",
      "         [[ 0.0271, -0.0113, -0.0013],\n",
      "          [ 0.0613, -0.0015, -0.0213],\n",
      "          [ 0.0074, -0.0310, -0.0492]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0017,  0.0118,  0.1067],\n",
      "          [-0.0173,  0.0398,  0.0954],\n",
      "          [-0.0355,  0.0081,  0.0791]],\n",
      "\n",
      "         [[ 0.0139, -0.0231, -0.0353],\n",
      "          [ 0.0939,  0.0917, -0.0296],\n",
      "          [ 0.0540,  0.0623, -0.0338]],\n",
      "\n",
      "         [[-0.0230, -0.0129, -0.0234],\n",
      "          [-0.0283,  0.0036, -0.0123],\n",
      "          [-0.0096, -0.0030, -0.0007]]],\n",
      "\n",
      "\n",
      "        [[[-0.0098, -0.0195, -0.0590],\n",
      "          [ 0.0193,  0.0700, -0.0237],\n",
      "          [ 0.0162,  0.0111, -0.0105]],\n",
      "\n",
      "         [[ 0.0495, -0.0214,  0.0033],\n",
      "          [ 0.0067,  0.0006,  0.0111],\n",
      "          [ 0.0052, -0.0036,  0.0070]],\n",
      "\n",
      "         [[-0.0054,  0.0119,  0.1077],\n",
      "          [ 0.0137, -0.0437,  0.1501],\n",
      "          [ 0.0174, -0.0563, -0.0851]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0088,  0.0102, -0.0288],\n",
      "          [ 0.0227,  0.0294, -0.0060],\n",
      "          [-0.0399, -0.0141, -0.0264]],\n",
      "\n",
      "         [[ 0.0475, -0.0254, -0.0116],\n",
      "          [-0.0202, -0.0545, -0.0077],\n",
      "          [-0.0243, -0.0460, -0.0076]],\n",
      "\n",
      "         [[-0.0309,  0.0080, -0.0231],\n",
      "          [-0.0591, -0.0572, -0.0511],\n",
      "          [-0.0422, -0.0646, -0.0585]]]])\n",
      "Layer 9\n",
      "Layer 9 weights shape post-quantization: torch.Size([256, 384, 3, 3])\n",
      "Weights: tensor([[[[ 2.9710e-02, -1.1463e-02, -1.8013e-02],\n",
      "          [-2.4456e-02, -7.7027e-03,  2.0027e-02],\n",
      "          [-2.4561e-02,  2.5994e-02, -1.4123e-02]],\n",
      "\n",
      "         [[ 4.1908e-02,  1.3529e-02,  1.6169e-02],\n",
      "          [-2.2870e-02, -2.1617e-02, -3.9788e-02],\n",
      "          [ 2.3681e-03,  1.4564e-02,  1.5038e-02]],\n",
      "\n",
      "         [[-6.0752e-02, -6.1724e-02, -4.0825e-03],\n",
      "          [-4.3509e-02, -5.4264e-02, -6.2086e-02],\n",
      "          [-6.4150e-02, -7.1465e-02,  1.0129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5737e-02, -3.1227e-02,  3.6883e-03],\n",
      "          [-6.0875e-02, -2.4925e-02, -2.9239e-02],\n",
      "          [-7.5596e-02, -6.1906e-02, -5.8334e-02]],\n",
      "\n",
      "         [[ 1.0939e-02,  2.7346e-02, -4.0859e-02],\n",
      "          [-4.6136e-02, -3.3504e-02, -6.9754e-02],\n",
      "          [-4.3300e-03, -2.1179e-02, -5.9773e-02]],\n",
      "\n",
      "         [[-2.9914e-02,  5.4176e-03, -5.4176e-03],\n",
      "          [-8.3185e-03, -2.9771e-02, -5.5603e-02],\n",
      "          [ 3.0415e-02,  2.1794e-02, -1.2454e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5842e-03,  1.4716e-02,  3.8935e-02],\n",
      "          [-2.1614e-02,  1.7380e-02,  2.8299e-02],\n",
      "          [-2.3058e-02,  3.5712e-02,  9.5608e-03]],\n",
      "\n",
      "         [[-2.6368e-02, -2.5330e-02, -4.5676e-03],\n",
      "          [ 2.8185e-02,  2.4824e-03,  3.2839e-02],\n",
      "          [-6.9103e-02,  7.0736e-03, -9.2501e-03]],\n",
      "\n",
      "         [[ 3.6959e-02,  9.5791e-02,  5.8078e-02],\n",
      "          [ 2.7144e-02, -5.5571e-03, -1.0259e-02],\n",
      "          [-3.2591e-02, -1.8021e-02, -4.8695e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1435e-02, -9.4615e-03, -1.6639e-02],\n",
      "          [-3.3575e-03,  2.5082e-02,  5.3325e-03],\n",
      "          [ 3.9118e-04,  8.1496e-03,  1.3800e-02]],\n",
      "\n",
      "         [[ 4.8011e-02,  2.8731e-02, -2.4194e-05],\n",
      "          [ 3.9041e-03, -2.7546e-02, -2.3425e-02],\n",
      "          [-1.6024e-02,  1.6753e-02,  4.6252e-02]],\n",
      "\n",
      "         [[ 1.3962e-02,  3.1664e-02,  9.4743e-03],\n",
      "          [ 1.1744e-02, -2.3674e-02,  1.4353e-02],\n",
      "          [-9.9155e-03, -1.5357e-02, -1.0399e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6628e-02, -5.3834e-02, -4.5780e-02],\n",
      "          [-8.4130e-03,  5.4983e-03, -1.0599e-04],\n",
      "          [ 5.3858e-02,  1.5267e-03, -3.3926e-04]],\n",
      "\n",
      "         [[-8.7942e-03, -2.6649e-03, -1.6922e-02],\n",
      "          [ 4.8132e-03, -4.7753e-03,  2.2361e-03],\n",
      "          [ 8.0937e-03,  2.3805e-03,  1.5116e-02]],\n",
      "\n",
      "         [[ 1.0607e-02, -5.3451e-03,  7.0154e-03],\n",
      "          [-5.1646e-02, -5.8045e-02, -2.5595e-04],\n",
      "          [ 2.6330e-04, -2.4684e-02,  1.0450e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8651e-02,  2.9083e-03,  4.0148e-02],\n",
      "          [ 1.2628e-02,  1.2628e-02,  6.1651e-03],\n",
      "          [-2.6680e-02, -6.7226e-04, -1.8277e-02]],\n",
      "\n",
      "         [[-1.4052e-02, -1.8211e-02, -1.6347e-02],\n",
      "          [-5.8717e-03, -1.1233e-02, -3.2422e-02],\n",
      "          [ 1.4449e-02,  3.6701e-02,  2.1096e-02]],\n",
      "\n",
      "         [[-1.6893e-02,  4.9045e-03, -3.4604e-02],\n",
      "          [-6.4332e-03, -2.9826e-02, -3.7137e-02],\n",
      "          [ 6.9128e-02,  2.1773e-02,  3.0482e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.0143e-03,  2.1676e-02,  2.7806e-02],\n",
      "          [-1.2354e-02, -3.3261e-02, -4.0230e-02],\n",
      "          [-8.4402e-03, -1.3653e-02, -3.1527e-02]],\n",
      "\n",
      "         [[ 1.1345e-02,  1.9579e-02,  2.3239e-02],\n",
      "          [ 1.6813e-02,  1.0539e-02,  3.1869e-02],\n",
      "          [ 1.1708e-02,  2.0282e-02,  2.0942e-02]],\n",
      "\n",
      "         [[-3.5028e-02, -1.8479e-02, -1.8479e-02],\n",
      "          [-5.1196e-03,  3.4220e-02, -1.2125e-02],\n",
      "          [-1.4741e-02,  5.6999e-03, -2.4961e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9068e-02, -3.5684e-03, -3.8145e-03],\n",
      "          [ 5.5312e-03, -1.9228e-02, -3.3451e-02],\n",
      "          [ 3.8010e-03, -2.4136e-02, -1.5774e-02]],\n",
      "\n",
      "         [[ 6.8439e-02,  3.1256e-02, -6.0356e-04],\n",
      "          [ 7.0230e-02,  5.6958e-02, -3.5392e-03],\n",
      "          [ 1.8825e-02,  3.5682e-02,  1.8544e-02]],\n",
      "\n",
      "         [[-5.2495e-02, -6.6669e-02, -5.7219e-02],\n",
      "          [-2.6950e-02, -3.7203e-02, -3.3102e-02],\n",
      "          [-2.0645e-02, -2.1125e-02, -6.0975e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2507e-03, -2.5706e-02,  5.8700e-03],\n",
      "          [-3.7988e-02, -9.8710e-03,  3.7390e-02],\n",
      "          [-1.2362e-02,  9.4402e-03,  2.8545e-02]],\n",
      "\n",
      "         [[ 1.6756e-03,  2.6600e-02, -8.3779e-03],\n",
      "          [ 3.9983e-02,  2.7705e-02,  2.9594e-02],\n",
      "          [-3.5753e-02,  3.8480e-02, -2.0906e-02]],\n",
      "\n",
      "         [[ 3.1157e-02,  5.6527e-02,  1.5578e-02],\n",
      "          [-1.6094e-02, -4.6454e-02, -6.5841e-03],\n",
      "          [-3.6752e-02, -4.2432e-02, -3.4079e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8526e-03, -1.6806e-02, -3.4406e-03],\n",
      "          [-1.0953e-03, -1.9319e-02, -1.3995e-02],\n",
      "          [ 4.5715e-03,  1.8728e-02,  1.2535e-02]],\n",
      "\n",
      "         [[ 3.2936e-02,  2.4378e-02,  2.2044e-02],\n",
      "          [ 5.6796e-02,  4.7851e-02, -6.7081e-03],\n",
      "          [ 2.9127e-02, -4.5869e-03, -1.2843e-02]],\n",
      "\n",
      "         [[ 2.2576e-03,  2.5600e-02, -1.4513e-02],\n",
      "          [ 5.1452e-03, -1.2329e-02, -9.0284e-03],\n",
      "          [-2.3260e-02, -6.4218e-02, -2.0732e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6385e-02,  3.1382e-02,  3.5270e-02],\n",
      "          [-1.4682e-02, -5.6505e-02, -2.2246e-02],\n",
      "          [ 1.3433e-02, -8.3561e-03,  3.7021e-03]],\n",
      "\n",
      "         [[ 2.3428e-02,  2.4388e-02,  1.8819e-02],\n",
      "          [-7.0710e-03,  1.6328e-02,  9.2565e-03],\n",
      "          [-6.2928e-02, -2.5766e-02, -4.5090e-02]],\n",
      "\n",
      "         [[-5.5822e-02, -4.1317e-02,  1.6263e-02],\n",
      "          [-8.3501e-02, -5.8516e-02,  2.6299e-02],\n",
      "          [-7.3335e-02,  7.5067e-03,  5.1970e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1869e-02,  3.0584e-02,  5.7973e-02],\n",
      "          [ 2.0208e-03, -5.3466e-02,  5.4729e-03],\n",
      "          [ 2.5138e-02,  3.4328e-02,  3.7842e-03]],\n",
      "\n",
      "         [[-2.8571e-02, -2.0022e-02,  1.3048e-02],\n",
      "          [ 1.1008e-02, -8.4793e-03, -1.8892e-02],\n",
      "          [-1.4672e-02,  2.1539e-02,  3.9645e-02]],\n",
      "\n",
      "         [[-7.4787e-03, -9.2839e-03, -3.2751e-02],\n",
      "          [-3.6071e-02,  3.8176e-02, -1.0821e-02],\n",
      "          [-3.7370e-03,  5.9325e-02, -1.1678e-02]]]])\n",
      "Layer 11\n",
      "Layer 11 weights shape post-quantization: torch.Size([256, 256, 3, 3])\n",
      "Weights: tensor([[[[-0.0335, -0.0151, -0.0182],\n",
      "          [-0.0390, -0.0597, -0.0249],\n",
      "          [-0.0054, -0.0390, -0.0570]],\n",
      "\n",
      "         [[ 0.0067,  0.0242,  0.0010],\n",
      "          [ 0.0141,  0.0352,  0.0291],\n",
      "          [-0.0142,  0.0359, -0.0383]],\n",
      "\n",
      "         [[-0.0147, -0.0299, -0.0333],\n",
      "          [-0.0080, -0.0377, -0.0178],\n",
      "          [ 0.0792,  0.0430,  0.0698]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0267, -0.0320,  0.0161],\n",
      "          [-0.0126, -0.0594, -0.0224],\n",
      "          [ 0.0152, -0.0051,  0.0033]],\n",
      "\n",
      "         [[-0.0143, -0.0159, -0.0336],\n",
      "          [-0.0296, -0.0545, -0.0292],\n",
      "          [ 0.0036,  0.0098,  0.0088]],\n",
      "\n",
      "         [[ 0.0072, -0.0066,  0.0044],\n",
      "          [ 0.0076,  0.0037,  0.0186],\n",
      "          [ 0.0080,  0.0007,  0.0102]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0023,  0.0120,  0.0025],\n",
      "          [ 0.0035, -0.0185,  0.0322],\n",
      "          [ 0.0142,  0.0441,  0.0029]],\n",
      "\n",
      "         [[ 0.0468,  0.0191, -0.0021],\n",
      "          [ 0.0476,  0.0278,  0.0184],\n",
      "          [ 0.0732,  0.0438,  0.0109]],\n",
      "\n",
      "         [[-0.0132, -0.0240, -0.0068],\n",
      "          [-0.0030,  0.0165,  0.0214],\n",
      "          [ 0.0525,  0.0732,  0.0732]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0624, -0.0800, -0.0756],\n",
      "          [-0.0774, -0.0579, -0.0524],\n",
      "          [-0.0671, -0.0671, -0.0597]],\n",
      "\n",
      "         [[-0.0494, -0.0210,  0.0045],\n",
      "          [-0.0414, -0.0017, -0.0287],\n",
      "          [-0.0381, -0.0168, -0.0345]],\n",
      "\n",
      "         [[-0.0144, -0.0215, -0.0146],\n",
      "          [-0.0185, -0.0112, -0.0066],\n",
      "          [-0.0302, -0.0283, -0.0038]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0003, -0.0298, -0.0364],\n",
      "          [-0.0139, -0.0477,  0.0083],\n",
      "          [ 0.0013, -0.0703, -0.0282]],\n",
      "\n",
      "         [[ 0.0185,  0.0179, -0.0153],\n",
      "          [ 0.0116, -0.0125,  0.0019],\n",
      "          [ 0.0216, -0.0153, -0.0116]],\n",
      "\n",
      "         [[ 0.0382, -0.0364,  0.0093],\n",
      "          [-0.0112, -0.0293,  0.0383],\n",
      "          [ 0.0169,  0.0036,  0.0438]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0244, -0.0440, -0.0517],\n",
      "          [-0.0209, -0.0395, -0.0233],\n",
      "          [-0.0504, -0.0674, -0.0101]],\n",
      "\n",
      "         [[-0.0202,  0.0002, -0.0256],\n",
      "          [ 0.0025, -0.0420, -0.0305],\n",
      "          [-0.0294,  0.0067, -0.0079]],\n",
      "\n",
      "         [[ 0.0136, -0.0222, -0.0183],\n",
      "          [ 0.0073,  0.0044,  0.0054],\n",
      "          [ 0.0251,  0.0336, -0.0101]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0297,  0.0091, -0.0022],\n",
      "          [-0.0322, -0.0660,  0.0002],\n",
      "          [ 0.0174, -0.0166, -0.0245]],\n",
      "\n",
      "         [[-0.0104, -0.0192,  0.0237],\n",
      "          [ 0.0072, -0.0506,  0.0064],\n",
      "          [ 0.0158,  0.0218,  0.0503]],\n",
      "\n",
      "         [[-0.0191, -0.0735, -0.0032],\n",
      "          [-0.0217, -0.0255, -0.0157],\n",
      "          [-0.0057, -0.0035, -0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0911,  0.0077,  0.0466],\n",
      "          [-0.0096, -0.0763, -0.0162],\n",
      "          [ 0.0171, -0.0747, -0.0042]],\n",
      "\n",
      "         [[-0.0203,  0.0106, -0.1121],\n",
      "          [ 0.0181,  0.0442,  0.0022],\n",
      "          [ 0.0294,  0.0612, -0.0145]],\n",
      "\n",
      "         [[-0.0144, -0.0508, -0.0180],\n",
      "          [ 0.0252,  0.0089, -0.0174],\n",
      "          [ 0.0052,  0.0415, -0.0186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0002, -0.0140, -0.0081],\n",
      "          [-0.0081, -0.0211, -0.0091],\n",
      "          [-0.0171, -0.0588, -0.0491]],\n",
      "\n",
      "         [[ 0.0147, -0.0426, -0.0060],\n",
      "          [-0.0077, -0.0316, -0.0361],\n",
      "          [-0.0156, -0.0093, -0.0166]],\n",
      "\n",
      "         [[-0.0218, -0.0314, -0.0149],\n",
      "          [ 0.0164, -0.0222, -0.0392],\n",
      "          [-0.0487, -0.0441, -0.0073]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0279, -0.0196,  0.0097],\n",
      "          [-0.0078, -0.0299,  0.0080],\n",
      "          [-0.0447, -0.0243,  0.0303]],\n",
      "\n",
      "         [[-0.0075, -0.0088, -0.0330],\n",
      "          [-0.0254, -0.0419, -0.0083],\n",
      "          [-0.0324, -0.0496, -0.0078]],\n",
      "\n",
      "         [[-0.0589, -0.0584, -0.0422],\n",
      "          [-0.0202, -0.0523, -0.0276],\n",
      "          [-0.0274, -0.0400, -0.0164]]],\n",
      "\n",
      "\n",
      "        [[[-0.0144, -0.0510, -0.0201],\n",
      "          [ 0.0069, -0.0105, -0.0230],\n",
      "          [-0.0152,  0.0012, -0.0192]],\n",
      "\n",
      "         [[-0.0085,  0.0015, -0.0598],\n",
      "          [-0.0143,  0.0364, -0.0226],\n",
      "          [ 0.0311,  0.0299,  0.0216]],\n",
      "\n",
      "         [[-0.0537, -0.0152, -0.0224],\n",
      "          [-0.0542, -0.0499, -0.0337],\n",
      "          [-0.0270, -0.0114, -0.0309]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0170, -0.0442, -0.0254],\n",
      "          [ 0.0395, -0.0127,  0.0137],\n",
      "          [-0.0256, -0.0279, -0.0329]],\n",
      "\n",
      "         [[ 0.0049,  0.0415,  0.0029],\n",
      "          [-0.0032,  0.0530,  0.0467],\n",
      "          [-0.0151, -0.0202, -0.0492]],\n",
      "\n",
      "         [[-0.0127, -0.0035,  0.0106],\n",
      "          [-0.0011, -0.0099,  0.0087],\n",
      "          [-0.0078,  0.0331,  0.0182]]]])\n",
      "Layer 15\n",
      "Layer 18\n",
      "Layer 20\n"
     ]
    }
   ],
   "source": [
    "if not DEBUG:\n",
    "    count = 0\n",
    "    for layer in [*alexnet.features,*alexnet.classifier]:\n",
    "        count += 1\n",
    "        try:\n",
    "            if len(layer.weight.shape) == 4:\n",
    "                weights = layer.weight.detach()\n",
    "                print(f'Layer {count}')# weights shape pre-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                for filter in range(0, weights.shape[0]):\n",
    "                    # print(f'Filter num {filter}')\n",
    "                    for channel in range(0, weights.shape[1]):\n",
    "                        # print(f'Channel num {channel}')\n",
    "                        # print(layer.weight[filter,channel])\n",
    "                        weights[filter,channel] = quantize_dequantize_dt(weights[filter,channel])\n",
    "                        # for row in range(0,weights.shape[2]):\n",
    "                        #     weights[filter,channel, row] = quantize_dequantize_dt(weights[filter,channel,row])\n",
    "                        # print(f'Finish window')\n",
    "                # print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                # layer.weight = nn.parameter.Parameter(weights)\n",
    "                print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                layer.weight = nn.parameter.Parameter(weights)\n",
    "            else:\n",
    "                weights = layer.weight.detach()\n",
    "                print(f'Layer {count}')# weights shape pre-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "                weights = quantize_dequantize_dt(weights)\n",
    "                # for row in tqdm(range(0,weights.shape[0])):\n",
    "                #     weights[row] = quantize_dequantize_dt(weights[row])\n",
    "                layer.weight = nn.parameter.Parameter(weights)\n",
    "                # print(f'Layer {count} weights shape post-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "                # print(layer.weight)\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "else:\n",
    "    count = 0\n",
    "    for layer in alexnet.classifier:\n",
    "        count += 1\n",
    "        try:\n",
    "            if len(layer.weight.shape) == 4:\n",
    "                weights = layer.weight.detach()\n",
    "                print(f'Layer {count} weights shape pre-quantization: {weights.shape}')\n",
    "                \n",
    "                for filter in range(0, layer.weight.shape[0]):\n",
    "                    for channel in range(0, layer.weight.shape[1]):\n",
    "                        # print(layer.weight[filter,channel])\n",
    "                        weights[filter,channel] = quantize_dequantize_dt(weights[filter,channel])\n",
    "                print(f'Layer {count} weights shape post-quantization: {weights.shape}')\n",
    "                layer.weight = nn.parameter.Parameter(weights)\n",
    "            else:\n",
    "                print(f'In else loop')\n",
    "                print(f'Layer {count} weights shape pre-quantization: {layer.weight.shape}')\n",
    "                intermediate = quantize_dequantize_dt(layer.weight.detach())\n",
    "                print(intermediate.shape)\n",
    "                layer.weight = nn.parameter.Parameter(intermediate)\n",
    "                print(f'Layer {count} weights shape post-quantization: {layer.weight.shape}')\n",
    "                # print(layer.weight)\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "\n",
    "# for layer in [*alexnet.features,*alexnet.classifier]:\n",
    "#     try:\n",
    "#         if len(layer.weight.shape) == 4:\n",
    "#         for filter in range(0, layer.weight.shape[0]):\n",
    "#             for channel in \n",
    "#         layer.weight = nn.parameter.Parameter(quantize_dequantize_dt(layer.weight.detach()))\n",
    "#     except (TypeError, AttributeError):\n",
    "#         print(layer)\n",
    "\n",
    "# for layer in [*alexnet.features,*alexnet.classifier]:\n",
    "#     try:\n",
    "#         if len(layer.weight.shape) == 4:\n",
    "#         for filter in range(0, layer.weight.shape[0]):\n",
    "#             for channel in \n",
    "#         layer.weight = nn.parameter.Parameter(quantize_dequantize_dt(layer.weight.detach()))\n",
    "#     except (TypeError, AttributeError):\n",
    "#         print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa1a43e3-f0d1-4768-947e-873d3e33bc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if Test:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    alexnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6ff5bc-f132-40a9-922b-79684bba442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82.22 %\n"
     ]
    }
   ],
   "source": [
    "# DT QUANTIZATION\n",
    "if Test:\n",
    "    #Testing Accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = alexnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2f03887-6741-49d1-a025-d6401ab3ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2500/2500 [00:16<00:00, 150.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82.23 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# NO QUANTIZATION\n",
    "if Test:\n",
    "    #Testing Accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = alexnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35c1422e-6b56-42cc-87a3-3a6ed13d4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab861791-a886-43a1-9c9c-ddff5838c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_{}_{}'.format(timestamp, \"DT_Quantized_NEW\")\n",
    "torch.save(alexnet.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5b104-517b-4f83-aeb8-e37ea7bb2949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e378015-a51b-486f-ae8f-1270bfc113c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c2c5e7a-09a0-460e-8ea8-eccf05cdc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9653e440-8dca-45e2-bc32-a2da218365b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c08752d-7d76-480a-a8e3-94b3c444574c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Elijah/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "\n",
    "alexnet.classifier[4] = nn.Linear(4096,1024)\n",
    "alexnet.classifier[6] = nn.Linear(1024,10)\n",
    "\n",
    "\n",
    "alexnet.load_state_dict(torch.load('model_20240603_151633_final_frozen_alexnet'))\n",
    "alexnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b695d628-e2c5-4457-8c6d-9314f068a048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alexnet.features[0].weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51462db1-837b-4502-8128-6497685f02e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # quantize_requantize(alexnet.features[0].weight.detach(), torch.float32, torch.int8)\n",
    "# type(torch.finfo(torch.float32).max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed710303-9192-4844-8aba-764bfcbd2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minmax(dt):\n",
    "    try:\n",
    "        max = torch.finfo(dt).max\n",
    "        min = torch.finfo(dt).min\n",
    "    except:\n",
    "        max = torch.iinfo(dt).max\n",
    "        min = torch.iinfo(dt).min\n",
    "    return min,max\n",
    "    \n",
    "def quantize_requantize(mat, initial_dt, target_dt):\n",
    "    i_bounds = (torch.min(mat), torch.max(mat))\n",
    "    t_bounds = get_minmax(target_dt)\n",
    "    S = np.float128(t_bounds[1] - t_bounds[0]) / np.float128(i_bounds[1] - i_bounds[0])\n",
    "    print(S)\n",
    "    # mat.apply_(lambda x: (x * S))\n",
    "    mat *= S\n",
    "    mat = mat.to(target_dt)\n",
    "    # print(mat)\n",
    "    mat = mat.to(initial_dt)\n",
    "    mat /= S\n",
    "    # mat.apply_(lambda x: (x / S))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a5914e-cf1c-477e-ad44-323afe284e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_minmax(dt):\n",
    "#     try:\n",
    "#         max = torch.finfo(dt).max\n",
    "#         min = torch.finfo(dt).min\n",
    "#     except:\n",
    "#         max = torch.iinfo(dt).max\n",
    "#         min = torch.iinfo(dt).min\n",
    "#     return min,max\n",
    "    \n",
    "# def calc_sf(mat, initial_dt, target_dt): \n",
    "#     i_bounds = (torch.min(mat), torch.max(mat))\n",
    "#     t_bounds = get_minmax(target_dt)\n",
    "#     S = (t_bounds[1] - t_bounds[0]) / (i_bounds[1] - i_bounds[0])\n",
    "#     return S\n",
    "\n",
    "# def block_linear_quantization(mat: torch.tensor , block_size, initial_dt, target_dt, orig_shape = None):\n",
    "#     if orig_shape == None:\n",
    "#         orig_shape = mat.shape\n",
    "#     if len(mat.shape) > 2:\n",
    "#         for i in range(mat.shape[0]):\n",
    "#             mat[i] = block_linear_quantization(mat[i], block_size, initial_dt, target_dt, orig_shape)\n",
    "#     else:\n",
    "#         # test without need for padding\n",
    "#         start_ix = 0\n",
    "#         start_iy = 0\n",
    "#         # Padding operation\n",
    "#         if orig_shape[-2] % block_size != 0:\n",
    "#             start_ix -= orig_shape[-2] % block_size\n",
    "#         if orig_shape[-1] % block_size != 0:\n",
    "#             start_iy -= orig_shape[-1] % block_size\n",
    "#         for x in range(start_ix,mat.shape[-2]):\n",
    "#             for y in range(start_iy,mat.shape[-1]):\n",
    "#                 submat = mat[x:x + block_size, y:y + block_size]\n",
    "#                 S = calc_sf(submat,torch.float32, torch.int8)\n",
    "#                 mat[x:x + block_size, y:y + block_size] = submat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02dcb7-4e06-4c4a-9a86-1be973debb9d",
   "metadata": {},
   "source": [
    "# Per Tensor Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78d828b0-7323-4728-897a-21024afcdcdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 1.1863e-01,  9.4048e-02,  9.5411e-02,  ...,  5.5816e-02,\n",
      "            2.1566e-02,  4.9946e-02],\n",
      "          [ 7.4867e-02,  3.8940e-02,  5.2960e-02,  ...,  2.5707e-02,\n",
      "           -1.1294e-02,  4.1403e-03],\n",
      "          [ 7.5417e-02,  3.8757e-02,  5.4925e-02,  ...,  4.3578e-02,\n",
      "            1.0220e-02,  1.3233e-02],\n",
      "          ...,\n",
      "          [ 9.3131e-02,  1.0372e-01,  6.7529e-02,  ..., -2.0275e-01,\n",
      "           -1.2838e-01, -1.1218e-01],\n",
      "          [ 4.3526e-02,  6.4909e-02,  3.6162e-02,  ..., -2.0246e-01,\n",
      "           -1.1375e-01, -1.0718e-01],\n",
      "          [ 4.7352e-02,  6.2524e-02,  2.4737e-02,  ..., -1.1842e-01,\n",
      "           -9.5542e-02, -8.3881e-02]],\n",
      "\n",
      "         [[-7.2613e-02, -5.7991e-02, -8.0658e-02,  ..., -6.0271e-04,\n",
      "           -2.5287e-02,  2.5471e-02],\n",
      "          [-6.9023e-02, -6.7555e-02, -7.6360e-02,  ..., -3.9569e-03,\n",
      "           -3.0397e-02,  1.0456e-02],\n",
      "          [-9.9499e-02, -8.5584e-02, -1.0519e-01,  ..., -2.6571e-02,\n",
      "           -2.2772e-02,  6.6298e-03],\n",
      "          ...,\n",
      "          [-1.5120e-01, -8.8729e-02, -9.6721e-02,  ...,  3.0851e-01,\n",
      "            1.8094e-01,  8.4274e-02],\n",
      "          [-1.4308e-01, -7.5705e-02, -7.2194e-02,  ...,  2.0416e-01,\n",
      "            1.6446e-01,  9.5149e-02],\n",
      "          [-8.5899e-02, -4.0119e-02, -5.1466e-02,  ...,  1.6349e-01,\n",
      "            1.4821e-01,  1.0194e-01]],\n",
      "\n",
      "         [[-2.3584e-02, -2.1226e-03, -2.7751e-02,  ...,  3.9936e-02,\n",
      "           -7.1014e-03,  3.2205e-02],\n",
      "          [ 2.3584e-04,  2.2457e-02,  8.8834e-03,  ...,  1.8762e-02,\n",
      "           -1.4150e-02,  1.8265e-02],\n",
      "          [ 5.3981e-03,  2.9375e-02,  3.1446e-04,  ...,  1.2028e-02,\n",
      "           -2.5156e-03,  8.3331e-03],\n",
      "          ...,\n",
      "          [-6.2812e-02, -1.1635e-02, -6.2079e-02,  ...,  1.0330e-01,\n",
      "           -9.4861e-03, -7.9557e-02],\n",
      "          [-4.5675e-02,  3.3542e-03, -3.9621e-02,  ..., -2.6440e-02,\n",
      "           -3.3489e-02, -7.6386e-02],\n",
      "          [-1.8684e-02,  1.1347e-02, -3.9648e-02,  ..., -6.8551e-02,\n",
      "           -4.1272e-02, -5.5449e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9915e-03,  2.9087e-03,  4.8190e-02,  ...,  6.1397e-02,\n",
      "            2.6100e-02,  1.9549e-02],\n",
      "          [-1.2578e-02, -4.8741e-03,  1.8474e-02,  ...,  5.3877e-02,\n",
      "            1.6352e-02,  2.3768e-02],\n",
      "          [ 3.6424e-03, -7.5993e-04,  2.6336e-02,  ..., -2.5838e-02,\n",
      "           -6.1790e-02,  2.6100e-02],\n",
      "          ...,\n",
      "          [-1.0796e-02, -4.5858e-03,  1.5120e-02,  ...,  2.9559e-02,\n",
      "            5.3195e-03,  6.8551e-02],\n",
      "          [ 2.6205e-04, -1.4832e-02,  7.8090e-03,  ...,  2.7148e-02,\n",
      "           -1.8081e-02,  5.2462e-02],\n",
      "          [-5.2462e-02, -4.6566e-02, -1.0927e-02,  ...,  4.2976e-03,\n",
      "           -2.6205e-03,  1.4386e-02]],\n",
      "\n",
      "         [[ 2.3951e-02,  2.2719e-02,  5.7388e-03,  ...,  7.2063e-03,\n",
      "           -2.4632e-02,  4.4653e-02],\n",
      "          [ 2.6912e-02,  4.4888e-02, -1.0744e-03,  ...,  4.4233e-02,\n",
      "           -2.1147e-02,  6.4516e-02],\n",
      "          [ 1.2421e-02,  1.0246e-02, -4.1534e-02,  ..., -1.2133e-01,\n",
      "           -1.6294e-01,  2.6257e-02],\n",
      "          ...,\n",
      "          [ 3.5900e-02,  5.3222e-02,  1.1006e-02,  ...,  1.2709e-02,\n",
      "           -2.9716e-02,  8.5925e-02],\n",
      "          [ 1.5618e-02,  2.1724e-02, -8.2807e-03,  ..., -3.2494e-03,\n",
      "           -5.4086e-02,  5.7624e-02],\n",
      "          [ 7.5233e-02,  8.7759e-02,  5.5790e-02,  ...,  5.2828e-02,\n",
      "            1.0587e-02,  9.3524e-02]],\n",
      "\n",
      "         [[-3.6477e-02,  6.6298e-03, -3.9019e-02,  ..., -1.5670e-02,\n",
      "           -7.9976e-02, -8.6475e-04],\n",
      "          [-5.1623e-03,  5.7388e-02,  8.9620e-03,  ...,  7.4159e-02,\n",
      "           -3.1708e-03,  4.2766e-02],\n",
      "          [-7.9426e-02, -2.2903e-02, -7.3347e-02,  ..., -5.6733e-02,\n",
      "           -1.2921e-01,  1.8894e-02],\n",
      "          ...,\n",
      "          [-3.9386e-02,  3.0974e-02, -2.7882e-02,  ..., -1.6771e-02,\n",
      "           -1.0236e-01,  4.0119e-02],\n",
      "          [-6.0742e-02, -2.3008e-02, -7.6832e-02,  ..., -7.9059e-02,\n",
      "           -1.6194e-01, -1.3731e-02],\n",
      "          [ 7.9400e-03,  4.6959e-02, -1.2447e-02,  ..., -4.6932e-02,\n",
      "           -1.0081e-01,  1.9811e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1702e-02,  1.3810e-02,  9.0406e-03,  ..., -9.6381e-02,\n",
      "           -1.1276e-01, -2.1595e-01],\n",
      "          [-9.0065e-02, -1.3129e-02, -3.2808e-02,  ..., -7.5260e-02,\n",
      "           -1.4800e-01, -2.9965e-01],\n",
      "          [-1.3155e-01, -4.2661e-02, -4.7719e-02,  ...,  2.1428e-01,\n",
      "            3.2520e-02, -1.7148e-01],\n",
      "          ...,\n",
      "          [-1.0621e-01, -9.7953e-02, -2.5549e-01,  ...,  1.2277e-01,\n",
      "            1.9287e-01,  1.2670e-01],\n",
      "          [-8.0736e-02, -6.1476e-02, -2.2311e-01,  ...,  3.5350e-02,\n",
      "            1.0532e-01,  1.0668e-01],\n",
      "          [ 3.8180e-02,  4.9946e-02, -1.2801e-01,  ..., -3.2913e-02,\n",
      "            1.8684e-02,  4.7142e-02]],\n",
      "\n",
      "         [[ 3.8992e-02,  6.4201e-03, -3.1708e-03,  ..., -2.1226e-02,\n",
      "            4.0512e-02,  1.1090e-01],\n",
      "          [ 6.5669e-02,  2.2117e-02,  6.6298e-03,  ..., -3.9438e-02,\n",
      "            2.7724e-02,  1.1404e-01],\n",
      "          [ 7.7932e-02,  4.0198e-02,  1.4046e-02,  ..., -1.5416e-01,\n",
      "           -9.2266e-02,  3.4459e-02],\n",
      "          ...,\n",
      "          [ 1.2835e-01,  9.4441e-02,  1.4656e-01,  ..., -6.0061e-02,\n",
      "           -9.0878e-02, -6.1109e-02],\n",
      "          [ 1.2683e-01,  1.0042e-01,  1.3752e-01,  ..., -2.2484e-02,\n",
      "           -6.6638e-02, -1.9889e-02],\n",
      "          [ 8.0501e-02,  7.8195e-02,  9.8922e-02,  ...,  9.2764e-03,\n",
      "           -3.4616e-02, -1.2369e-02]],\n",
      "\n",
      "         [[ 1.1530e-02, -2.6991e-02,  1.4806e-02,  ...,  9.4808e-02,\n",
      "            1.2044e-01,  1.1024e-01],\n",
      "          [ 9.2502e-03, -2.6676e-02,  1.2211e-02,  ...,  8.7209e-02,\n",
      "            1.5435e-01,  1.8047e-01],\n",
      "          [ 6.9940e-02,  1.3233e-02,  4.7981e-02,  ..., -5.6838e-02,\n",
      "            3.2572e-02,  1.6810e-01],\n",
      "          ...,\n",
      "          [-1.2185e-02, -3.3254e-02,  1.1284e-01,  ..., -6.7739e-02,\n",
      "           -1.0238e-01, -7.6177e-02],\n",
      "          [-6.0009e-03, -2.8615e-02,  1.1643e-01,  ..., -6.7346e-03,\n",
      "           -4.3762e-02, -3.1079e-02],\n",
      "          [-1.3354e-01, -1.4824e-01, -9.9577e-04,  ...,  1.8789e-02,\n",
      "           -6.4463e-03, -2.7043e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.0930e-03,  1.4806e-02,  4.7168e-03,  ...,  1.5539e-02,\n",
      "           -5.7650e-04, -1.9916e-02],\n",
      "          [ 2.8825e-04,  2.1226e-02, -1.3207e-02,  ...,  2.4370e-03,\n",
      "           -5.8436e-03, -2.0361e-02],\n",
      "          [-1.1032e-02,  1.0089e-02, -2.9611e-02,  ..., -1.4465e-02,\n",
      "           -1.7164e-02, -3.0528e-02],\n",
      "          ...,\n",
      "          [ 1.0010e-01,  9.1402e-02,  1.3076e-01,  ...,  1.5796e-01,\n",
      "            9.0353e-02,  7.8352e-02],\n",
      "          [ 1.1609e-01,  8.1837e-02,  8.2885e-02,  ..., -6.0166e-02,\n",
      "           -6.9390e-02, -5.0129e-02],\n",
      "          [-1.0563e-01, -1.1847e-01, -1.7680e-01,  ..., -2.0835e-01,\n",
      "           -1.8034e-01, -1.6690e-01]],\n",
      "\n",
      "         [[-1.1478e-02,  2.4894e-03, -8.2282e-03,  ..., -7.5731e-03,\n",
      "           -1.7374e-02, -1.7007e-02],\n",
      "          [-2.7253e-03, -1.1399e-02, -6.0533e-03,  ..., -2.8222e-02,\n",
      "           -2.2536e-02, -2.2536e-02],\n",
      "          [-8.4117e-03, -2.2274e-03, -3.5822e-02,  ..., -1.8448e-02,\n",
      "           -1.9784e-02, -2.4973e-02],\n",
      "          ...,\n",
      "          [ 1.2956e-01,  9.8031e-02,  1.4887e-01,  ...,  1.5655e-01,\n",
      "            7.9531e-02,  9.6905e-02],\n",
      "          [ 1.6079e-01,  1.0521e-01,  1.0262e-01,  ..., -6.5223e-02,\n",
      "           -6.4306e-02, -3.9045e-02],\n",
      "          [-1.2880e-01, -1.4654e-01, -1.9475e-01,  ..., -2.4176e-01,\n",
      "           -2.0275e-01, -1.9323e-01]],\n",
      "\n",
      "         [[-5.3981e-03, -1.7557e-03,  4.2976e-03,  ...,  9.8005e-03,\n",
      "            5.2147e-03,  6.3153e-03],\n",
      "          [ 9.3288e-03,  1.5723e-03, -2.1488e-03,  ...,  7.1014e-03,\n",
      "            9.1716e-04, -5.7388e-03],\n",
      "          [-1.3626e-03,  3.8783e-03, -7.7304e-03,  ...,  3.0397e-03,\n",
      "            1.4989e-02, -8.1496e-03],\n",
      "          ...,\n",
      "          [ 4.3919e-02,  7.8614e-04,  6.0611e-02,  ...,  7.4762e-02,\n",
      "            4.3945e-02,  5.6052e-02],\n",
      "          [ 1.0076e-01,  7.5102e-02,  1.0961e-01,  ...,  4.9789e-03,\n",
      "            1.0770e-02,  1.3391e-02],\n",
      "          [-8.8755e-02, -7.2770e-02, -9.2895e-02,  ..., -6.6507e-02,\n",
      "           -3.8966e-02, -4.8347e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5596e-03,  4.6906e-02, -1.6063e-02,  ...,  7.7566e-03,\n",
      "           -1.9784e-02,  6.7870e-03],\n",
      "          [ 6.2760e-02,  4.5098e-02,  4.7168e-02,  ...,  6.0585e-02,\n",
      "            2.9271e-02,  5.5790e-02],\n",
      "          [ 3.6686e-03,  1.2945e-02,  0.0000e+00,  ..., -8.3331e-03,\n",
      "           -1.9653e-03,  8.0710e-03],\n",
      "          ...,\n",
      "          [-4.4364e-02, -5.8856e-02, -2.4763e-02,  ..., -2.8406e-02,\n",
      "           -3.0895e-02, -5.2933e-02],\n",
      "          [-9.7481e-03, -4.3211e-02,  8.9882e-03,  ..., -4.2582e-02,\n",
      "           -1.8107e-02, -2.8013e-02],\n",
      "          [-2.1986e-02, -3.3568e-02,  1.3469e-02,  ..., -4.1508e-02,\n",
      "           -1.7793e-02, -5.1964e-02]],\n",
      "\n",
      "         [[-9.0589e-02, -5.1466e-02, -1.6459e-01,  ..., -1.1968e-01,\n",
      "           -1.1150e-01, -4.3893e-02],\n",
      "          [ 1.3810e-02,  2.5995e-02, -1.9418e-02,  ...,  2.3741e-02,\n",
      "            6.3677e-03,  5.4270e-02],\n",
      "          [-9.3210e-02, -4.7430e-02, -1.1273e-01,  ..., -8.6449e-02,\n",
      "           -7.3949e-02, -6.6586e-02],\n",
      "          ...,\n",
      "          [ 2.7358e-02,  1.0298e-02,  4.3893e-02,  ...,  2.7069e-02,\n",
      "            4.4495e-02,  1.5959e-02],\n",
      "          [ 9.8425e-02,  6.1424e-02,  1.1412e-01,  ...,  9.6381e-02,\n",
      "            1.0723e-01,  9.5699e-02],\n",
      "          [-1.5094e-02, -1.1818e-02,  4.8557e-02,  ...,  2.9035e-02,\n",
      "            5.6314e-02, -2.1488e-03]],\n",
      "\n",
      "         [[-1.3692e-01, -7.9321e-02, -2.1244e-01,  ..., -1.3632e-01,\n",
      "           -1.5123e-01, -6.3913e-02],\n",
      "          [ 1.5723e-02,  5.1440e-02, -1.8186e-02,  ...,  4.9081e-02,\n",
      "            1.9575e-02,  7.8090e-02],\n",
      "          [-1.7125e-01, -8.8729e-02, -1.7465e-01,  ..., -1.4431e-01,\n",
      "           -1.3362e-01, -1.1876e-01],\n",
      "          ...,\n",
      "          [ 5.1964e-02,  1.5906e-02,  6.9993e-02,  ...,  4.4391e-02,\n",
      "            6.5407e-02,  2.6912e-02],\n",
      "          [ 1.3142e-01,  9.1323e-02,  1.6226e-01,  ...,  1.4229e-01,\n",
      "            1.5497e-01,  1.3807e-01],\n",
      "          [ 3.7735e-03, -2.0361e-02,  7.8640e-02,  ...,  8.6030e-02,\n",
      "            1.2594e-01,  3.8757e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.5070e-02,  5.6576e-02,  1.4014e-01,  ..., -1.4806e-02,\n",
      "            1.0403e-02, -3.7735e-03],\n",
      "          [ 6.0402e-02,  1.2528e-01, -1.2363e-01,  ...,  7.8614e-02,\n",
      "           -1.0560e-02, -2.2222e-02],\n",
      "          [ 1.0304e-01, -1.3653e-01, -1.9598e-01,  ..., -5.1911e-02,\n",
      "           -8.3278e-02,  3.9674e-02],\n",
      "          ...,\n",
      "          [-1.8597e-01,  1.5461e-02,  3.3911e-01,  ...,  2.7507e-01,\n",
      "            1.0492e-01, -1.6860e-01],\n",
      "          [ 6.8263e-02,  1.3988e-01,  1.1347e-02,  ..., -7.8719e-02,\n",
      "           -2.4999e-01, -8.0055e-02],\n",
      "          [ 5.1623e-03, -6.8368e-02, -9.1926e-02,  ..., -1.0726e-01,\n",
      "            8.7969e-02,  1.0139e-01]],\n",
      "\n",
      "         [[-9.8739e-02,  6.2629e-02,  1.1493e-01,  ..., -1.3181e-02,\n",
      "            1.9549e-02, -1.0744e-03],\n",
      "          [ 8.3200e-02,  1.0298e-01, -1.5416e-01,  ...,  1.0862e-01,\n",
      "            1.2578e-02, -2.0256e-02],\n",
      "          [ 1.1247e-01, -1.6928e-01, -1.8875e-01,  ..., -6.3468e-02,\n",
      "           -9.3079e-02,  4.9003e-02],\n",
      "          ...,\n",
      "          [-1.8865e-01,  6.7372e-02,  4.8127e-01,  ...,  3.1370e-01,\n",
      "            1.6066e-01, -1.3448e-01],\n",
      "          [ 1.1205e-01,  2.0869e-01,  4.6801e-02,  ..., -7.0228e-03,\n",
      "           -2.2976e-01, -6.9521e-02],\n",
      "          [ 1.7243e-02, -9.1664e-02, -1.5940e-01,  ..., -8.0370e-02,\n",
      "            8.0029e-02,  1.1818e-01]],\n",
      "\n",
      "         [[-1.0579e-01,  5.4375e-02,  1.3047e-01,  ..., -3.9543e-02,\n",
      "            1.1923e-02, -2.7777e-03],\n",
      "          [ 5.7834e-02,  1.0644e-01, -1.3467e-01,  ...,  1.0644e-01,\n",
      "            1.8396e-02, -1.3102e-03],\n",
      "          [ 1.0395e-01, -1.0849e-01, -1.6758e-01,  ..., -4.2530e-02,\n",
      "           -8.5872e-02,  5.2566e-02],\n",
      "          ...,\n",
      "          [-1.8238e-01,  5.4217e-02,  3.9393e-01,  ...,  2.4431e-01,\n",
      "            1.0215e-01, -1.2874e-01],\n",
      "          [ 8.5715e-02,  1.8377e-01,  5.0313e-02,  ..., -4.6985e-02,\n",
      "           -2.1582e-01, -4.2478e-02],\n",
      "          [ 3.9595e-02, -7.6334e-02, -1.3501e-01,  ..., -4.8610e-02,\n",
      "            1.0063e-01,  9.0301e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 3.5967e-03,  1.4013e-03,  3.7181e-02, -2.0879e-02,  1.7750e-03],\n",
      "          [ 2.4102e-02, -1.2051e-02,  7.1140e-02, -8.5199e-02,  1.3032e-02],\n",
      "          [ 2.0926e-02, -1.0622e-01,  2.1533e-02, -6.9505e-02,  3.1576e-02],\n",
      "          [-8.3144e-03, -3.9003e-02, -4.6617e-02,  2.2094e-02, -1.3079e-03],\n",
      "          [-1.5368e-02,  8.6414e-03,  3.1436e-02,  1.6676e-02, -4.6710e-03]],\n",
      "\n",
      "         [[-5.4184e-03, -1.9058e-02, -3.2417e-02, -2.2000e-02, -1.2098e-02],\n",
      "          [-7.4736e-03,  3.0922e-02,  3.1856e-02, -7.6138e-03, -1.4714e-02],\n",
      "          [ 5.4651e-03,  8.0295e-02,  6.1237e-02,  1.3219e-02,  2.6204e-02],\n",
      "          [-2.6905e-02,  5.8855e-03,  3.8349e-02, -6.3059e-03,  3.9704e-03],\n",
      "          [ 2.0552e-03, -3.6247e-02, -2.1954e-03, -1.6535e-02,  5.6052e-03]],\n",
      "\n",
      "         [[-1.2565e-02, -5.9415e-02, -9.6270e-02,  1.6722e-02,  4.7457e-02],\n",
      "          [-1.4994e-02, -1.1210e-01, -2.3916e-02,  3.3444e-02,  4.1292e-02],\n",
      "          [-1.3826e-02,  4.1198e-02,  2.1575e-01,  2.9474e-02, -5.8901e-02],\n",
      "          [ 1.2285e-02,  1.0085e-01,  2.1907e-02, -1.4004e-01, -3.1249e-02],\n",
      "          [ 3.7835e-02,  5.2596e-02, -8.0341e-03, -8.1789e-02,  1.4340e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2705e-02,  2.5877e-02,  4.1712e-02, -1.3686e-02,  1.4480e-03],\n",
      "          [-1.0790e-02,  1.6395e-02,  8.1182e-02, -6.0116e-02, -5.1101e-02],\n",
      "          [-1.3733e-02, -5.3763e-02,  1.1052e-01,  3.8769e-03, -5.8855e-02],\n",
      "          [ 5.1381e-04,  2.3215e-02,  6.1564e-02,  5.4978e-02, -1.8777e-02],\n",
      "          [-3.9704e-03,  9.4354e-03, -2.7652e-02, -3.5967e-03, -6.3993e-03]],\n",
      "\n",
      "         [[-9.3420e-04, -5.7453e-03,  4.5636e-02,  1.4060e-02, -4.3534e-02],\n",
      "          [-4.3908e-03, -3.2837e-02,  4.1572e-02, -1.0977e-02,  2.3028e-02],\n",
      "          [ 1.7937e-02,  5.5585e-03, -4.6103e-02, -6.3292e-02,  2.5223e-02],\n",
      "          [ 5.1381e-03,  4.1058e-02,  2.1767e-02,  1.9431e-02,  3.1342e-02],\n",
      "          [-2.9521e-02, -3.0829e-03,  5.4931e-02,  3.5733e-02, -3.1296e-03]],\n",
      "\n",
      "         [[ 1.7283e-03,  1.5835e-02, -3.9563e-02, -8.6647e-02,  4.2366e-02],\n",
      "          [ 3.2744e-02,  2.0225e-02,  1.4396e-01, -1.5984e-01, -1.1519e-01],\n",
      "          [ 1.1631e-02, -1.3280e-01,  2.5051e-01,  1.9385e-01, -1.4718e-01],\n",
      "          [ 2.9848e-02, -7.6418e-02, -1.3298e-01,  1.2490e-01,  3.0455e-02],\n",
      "          [ 4.8672e-02,  7.8426e-02, -3.9283e-02,  4.8111e-03,  2.0366e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1673e-02, -4.7271e-02,  3.3912e-02,  6.8664e-03,  2.6204e-02],\n",
      "          [ 1.7656e-02, -5.2082e-02, -6.2825e-02, -3.3912e-02,  1.9104e-02],\n",
      "          [ 9.2019e-03, -2.8773e-02, -1.8721e-01, -1.9525e-02, -2.1066e-02],\n",
      "          [-1.4340e-02,  5.7500e-02, -4.1899e-02,  6.3526e-03,  4.2039e-04],\n",
      "          [ 1.2238e-02,  2.3075e-02, -2.2795e-02,  2.2888e-03, -6.3993e-03]],\n",
      "\n",
      "         [[ 4.6243e-03,  7.3802e-03, -4.1105e-02,  2.9801e-02, -1.8077e-02],\n",
      "          [ 9.5756e-03,  3.9844e-02, -4.1806e-02,  6.9131e-03, -2.5877e-02],\n",
      "          [-9.9960e-03,  5.4744e-02,  2.6718e-02,  7.0065e-03,  2.6905e-02],\n",
      "          [-9.5289e-03, -3.6060e-02,  1.4854e-02, -1.2565e-02, -1.8170e-02],\n",
      "          [-1.4013e-04, -6.3853e-02,  5.8014e-02,  2.8727e-02, -9.3420e-04]],\n",
      "\n",
      "         [[-4.5589e-02,  9.9306e-02,  2.0786e-02, -1.7610e-02,  4.2973e-03],\n",
      "          [-1.1304e-01,  1.0613e-01,  1.2299e-01, -1.5554e-02,  1.1911e-02],\n",
      "          [-8.6180e-02,  5.1568e-02,  2.8110e-01,  3.8302e-03,  3.9610e-02],\n",
      "          [ 2.7419e-02, -9.6316e-02,  1.6713e-01,  1.7843e-02, -3.1202e-02],\n",
      "          [ 3.8816e-02, -1.5013e-01,  9.5522e-02,  8.2070e-02, -2.6158e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1487e-03,  8.1743e-03,  2.2981e-02, -4.9513e-03, -2.2888e-02],\n",
      "          [ 4.4375e-03,  4.6617e-02,  3.4379e-02,  5.2502e-02, -1.8918e-02],\n",
      "          [-1.4200e-02,  5.9509e-02,  6.0256e-03,  3.6434e-02,  2.8026e-04],\n",
      "          [-2.9474e-02,  4.5869e-02,  5.4978e-02, -2.6625e-03,  4.2506e-03],\n",
      "          [-2.9708e-02, -1.6349e-02,  3.4425e-02, -9.1085e-03, -9.7624e-03]],\n",
      "\n",
      "         [[ 1.9992e-02, -4.4375e-03, -2.8353e-02,  7.3802e-03, -5.3250e-03],\n",
      "          [ 1.3032e-02, -2.9287e-02, -6.5955e-02,  3.1903e-02, -2.2888e-03],\n",
      "          [ 1.3966e-02, -5.7687e-02, -9.1505e-02,  2.8026e-03,  1.8684e-02],\n",
      "          [-1.8124e-02, -4.4982e-02, -9.9493e-03,  1.2331e-02, -1.4013e-03],\n",
      "          [ 3.3164e-03,  1.8264e-02,  1.2378e-02, -2.0412e-02,  2.4570e-02]],\n",
      "\n",
      "         [[-5.4184e-03,  4.2039e-04,  1.7423e-02, -2.2421e-03,  1.7283e-03],\n",
      "          [-1.0276e-02,  3.1342e-02, -2.5457e-02,  1.2845e-02, -7.0065e-04],\n",
      "          [-6.3059e-03,  7.3662e-02, -2.9334e-02,  4.9793e-02,  2.5784e-02],\n",
      "          [-1.9899e-02,  3.8489e-02,  3.0829e-02,  2.5223e-03, -4.3908e-03],\n",
      "          [ 1.7750e-03,  2.3075e-02,  4.6477e-02, -3.3958e-02, -1.1631e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0136e-02, -3.7835e-02, -4.6663e-02, -9.7624e-03,  3.7602e-02],\n",
      "          [ 1.4681e-01, -6.4927e-02, -3.7462e-02, -9.2486e-03,  2.3635e-02],\n",
      "          [ 1.8544e-02, -3.5313e-02, -9.6223e-03,  1.4200e-02,  2.7045e-02],\n",
      "          [-6.7263e-03,  2.8026e-03,  4.6710e-03,  4.7177e-03, -6.6328e-03],\n",
      "          [ 2.2141e-02, -1.2145e-03,  3.1109e-02,  3.1810e-02,  2.4289e-03]],\n",
      "\n",
      "         [[ 2.2935e-02, -3.2557e-02, -1.7890e-02,  5.2315e-03,  3.7368e-03],\n",
      "          [ 3.8676e-02, -8.8749e-02, -5.3717e-02, -2.4383e-02,  1.7329e-02],\n",
      "          [ 5.5492e-02, -7.1233e-02, -6.5347e-02, -3.7742e-02,  7.0999e-03],\n",
      "          [ 3.1529e-02, -6.1844e-02, -7.4409e-02, -3.4239e-02, -9.2486e-03],\n",
      "          [ 4.5075e-02, -8.4078e-03, -2.0506e-02, -1.4714e-02,  1.0276e-03]],\n",
      "\n",
      "         [[-9.5289e-03, -2.3168e-02, -1.4247e-02, -6.6795e-03, -2.8260e-02],\n",
      "          [ 1.6199e-01, -2.8213e-02, -2.4616e-02, -1.0136e-02, -2.4896e-02],\n",
      "          [ 8.9076e-02, -2.6812e-02, -3.7462e-02, -7.4736e-03, -1.9618e-03],\n",
      "          [-4.5262e-02, -1.7843e-02, -5.0914e-03,  1.7423e-02,  1.3966e-02],\n",
      "          [-2.0412e-02, -8.4078e-04,  1.3126e-02,  1.8217e-03, -5.4184e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5177e-02,  8.3611e-03, -3.4565e-03, -6.6795e-03,  9.4354e-03],\n",
      "          [ 1.4770e-01,  1.8264e-02, -8.2677e-03, -2.6625e-03, -2.9427e-03],\n",
      "          [ 1.8918e-02, -2.4570e-02, -2.5784e-02,  5.7453e-03,  1.5461e-02],\n",
      "          [ 1.0743e-02, -2.2421e-03,  1.3826e-02, -3.0362e-03, -1.4013e-03],\n",
      "          [ 3.5500e-03, -1.7096e-02, -2.0552e-03, -5.1381e-04, -1.1911e-02]],\n",
      "\n",
      "         [[-1.8030e-02,  5.5585e-03, -4.3908e-03, -6.4460e-03,  1.1117e-02],\n",
      "          [ 8.3004e-02, -8.5713e-02, -2.3682e-02,  2.7185e-02,  1.5321e-02],\n",
      "          [ 1.6255e-02, -5.0167e-02, -2.9381e-02, -5.6052e-04,  1.5041e-02],\n",
      "          [ 1.2238e-02,  6.5394e-03, -2.8493e-03, -2.0039e-02,  4.6243e-03],\n",
      "          [ 1.4574e-02, -9.5289e-03, -2.4570e-02, -2.4289e-03,  1.0276e-03]],\n",
      "\n",
      "         [[-1.7236e-02,  7.2868e-03,  1.0416e-02, -1.4901e-02, -6.8197e-03],\n",
      "          [ 6.2872e-02, -3.2557e-02,  5.7453e-03,  1.4527e-02, -6.1190e-03],\n",
      "          [ 7.3802e-03, -6.0817e-02, -1.0463e-02,  3.5967e-03, -1.4714e-02],\n",
      "          [-1.7236e-02,  1.5414e-03, -2.3869e-02, -9.7624e-03, -7.3802e-03],\n",
      "          [ 6.9131e-03,  7.1934e-03, -1.9058e-02, -6.6795e-03,  6.1190e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7563e-02,  1.0136e-02,  4.4795e-02, -2.6625e-03, -2.2654e-02],\n",
      "          [-1.5134e-02, -3.2697e-02,  1.4527e-02, -1.2799e-02, -3.2604e-02],\n",
      "          [-3.0221e-02, -3.2697e-02, -3.4005e-02, -2.0833e-02, -3.2650e-02],\n",
      "          [-4.1572e-03, -3.4565e-03, -1.0370e-02, -9.5756e-03, -3.1296e-03],\n",
      "          [ 1.1117e-02,  8.8282e-03,  1.8170e-02,  7.5203e-03,  1.5414e-03]],\n",
      "\n",
      "         [[-9.1552e-03,  1.0743e-03, -2.4009e-02, -1.7423e-02, -7.8473e-03],\n",
      "          [-1.5134e-02,  1.8124e-02,  1.3359e-02,  7.1186e-02,  5.8248e-02],\n",
      "          [-1.0977e-02,  1.5228e-02, -2.4850e-02, -4.0638e-03, -2.4803e-02],\n",
      "          [ 2.7092e-03,  1.6535e-02, -3.2604e-02, -5.6239e-02, -3.9937e-02],\n",
      "          [-4.6710e-04,  1.9852e-02, -3.3631e-03, -2.2141e-02, -9.5289e-03]],\n",
      "\n",
      "         [[-2.6531e-02, -4.6430e-02, -1.1126e-01, -6.3713e-02,  2.4149e-02],\n",
      "          [-3.1436e-02, -4.6710e-02, -5.0027e-02,  3.6621e-02,  8.7628e-02],\n",
      "          [ 2.4149e-02,  2.9287e-02,  5.9836e-02,  4.1992e-02, -2.5971e-02],\n",
      "          [ 2.5410e-02,  1.8217e-02,  4.0498e-02, -8.6414e-03, -6.0630e-02],\n",
      "          [ 1.2658e-02,  1.5321e-02,  3.3491e-02,  1.3312e-02, -2.3869e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5321e-02, -2.7419e-02, -3.7088e-02,  4.8065e-02,  1.0136e-02],\n",
      "          [-5.4604e-02, -6.3059e-02, -5.1802e-02,  6.3993e-02,  2.5784e-02],\n",
      "          [ 1.6769e-02,  1.3079e-02, -3.9517e-02, -1.1678e-03,  9.2486e-03],\n",
      "          [ 1.4994e-02,  1.2238e-02, -2.3355e-02, -2.8400e-02,  2.4896e-02],\n",
      "          [-4.0638e-03,  1.4433e-02,  6.2124e-03, -2.2514e-02, -2.0085e-03]],\n",
      "\n",
      "         [[-3.5219e-02,  8.0809e-03,  2.3495e-02, -1.0136e-02, -2.1487e-03],\n",
      "          [-3.4565e-02,  3.9704e-03,  1.3546e-02, -7.9781e-02, -5.2502e-02],\n",
      "          [-3.2697e-02,  3.4145e-02,  2.6578e-02, -2.3822e-03,  2.4896e-02],\n",
      "          [ 1.8030e-02,  4.6243e-03, -1.2005e-02,  8.8282e-03,  1.9338e-02],\n",
      "          [-2.9054e-02,  9.3420e-05, -1.7470e-02,  4.2973e-02,  6.6142e-02]],\n",
      "\n",
      "         [[ 4.6056e-02,  2.8400e-02, -2.6391e-02,  4.7177e-03, -7.6464e-02],\n",
      "          [ 7.5951e-02,  4.4281e-02, -5.8761e-02,  1.7843e-02,  9.6036e-02],\n",
      "          [ 5.8388e-02,  3.7555e-02, -6.7496e-02, -1.0309e-01, -2.3262e-02],\n",
      "          [ 4.3487e-02,  6.0630e-02,  6.2685e-02,  3.6901e-03, -5.8061e-02],\n",
      "          [ 4.6710e-05,  2.7139e-02,  4.3207e-02,  3.1156e-02, -5.8855e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5971e-02, -2.5737e-02, -2.7886e-02, -6.0116e-02, -2.1580e-02],\n",
      "          [ 5.8388e-03, -4.0591e-02, -9.7064e-02, -1.1318e-01, -4.5215e-02],\n",
      "          [-3.3024e-02, -1.7843e-02, -9.1365e-02, -1.0823e-01, -5.3390e-02],\n",
      "          [-1.4854e-02, -3.3164e-03, -2.7325e-02, -4.8532e-02, -4.1152e-02],\n",
      "          [ 8.8749e-04, -1.8170e-02, -3.1016e-02, -1.1818e-02, -2.6438e-02]],\n",
      "\n",
      "         [[ 7.2494e-02,  1.6395e-02, -1.5751e-01, -8.8843e-02, -2.1627e-02],\n",
      "          [ 9.2252e-02,  8.5620e-02, -6.8570e-02, -7.8333e-02, -9.3327e-02],\n",
      "          [ 1.1664e-01,  1.4293e-01,  1.4620e-02, -6.6562e-02, -1.8651e-01],\n",
      "          [ 4.0404e-02,  8.7862e-02,  4.2506e-02, -8.8749e-03, -1.2439e-01],\n",
      "          [ 2.0225e-02,  6.5815e-02,  9.6503e-02,  5.8668e-02, -7.2681e-02]],\n",
      "\n",
      "         [[-3.7788e-02, -1.1210e-02, -8.1743e-03,  1.2705e-02,  6.8477e-02],\n",
      "          [-4.4375e-03, -9.6223e-03, -3.2604e-02,  2.8960e-03,  3.7462e-02],\n",
      "          [ 3.3585e-02,  4.8438e-02,  2.6858e-02, -6.1144e-02, -2.0973e-02],\n",
      "          [-1.9665e-02,  6.9598e-03,  4.1992e-02, -4.3908e-02, -7.6371e-02],\n",
      "          [ 8.3144e-03,  2.5223e-03,  2.8026e-02, -3.4846e-02, -8.6647e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2658e-02, -1.5321e-02,  1.6489e-02,  3.3304e-02,  1.3032e-02],\n",
      "          [ 1.6349e-03, -1.8918e-02, -3.6107e-02,  3.2323e-02,  5.0120e-02],\n",
      "          [-1.3593e-02, -3.3678e-02, -7.9220e-02, -5.1381e-03,  6.5067e-02],\n",
      "          [-1.3079e-03,  1.9151e-02, -1.2145e-03, -1.5368e-02,  9.9025e-03],\n",
      "          [-8.5947e-03, -6.4460e-03,  4.4375e-03, -7.4736e-04,  2.6718e-02]],\n",
      "\n",
      "         [[-3.1342e-02, -6.5534e-02, -4.5542e-02,  2.9661e-02,  5.0447e-02],\n",
      "          [ 2.6345e-02, -6.4927e-03, -1.4298e-01, -2.9194e-02,  1.1678e-03],\n",
      "          [ 5.2409e-02,  6.1097e-02, -2.8540e-02, -1.0996e-01, -3.4612e-02],\n",
      "          [ 1.5975e-02,  3.1903e-02,  7.6978e-02, -1.1584e-02, -5.6940e-02],\n",
      "          [ 4.9326e-02, -1.5601e-02,  4.2740e-02,  3.7788e-02, -2.6812e-02]],\n",
      "\n",
      "         [[ 9.0151e-03,  1.5881e-03,  9.9493e-03,  2.6064e-02,  6.8197e-03],\n",
      "          [ 1.0603e-02, -6.1190e-03, -9.2486e-03,  1.8030e-02,  2.2654e-02],\n",
      "          [ 2.8960e-02,  9.3420e-05, -1.6722e-02, -1.9618e-03,  3.1436e-02],\n",
      "          [ 1.8918e-02,  2.8587e-02,  5.6052e-04, -1.0556e-02,  1.1070e-02],\n",
      "          [ 5.4651e-03, -6.3526e-03,  2.9427e-03, -2.7325e-02, -2.4429e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0065e-03, -2.0693e-02, -1.9058e-02, -2.8026e-03,  9.0618e-03],\n",
      "          [-2.2187e-02, -3.6481e-02, -3.3398e-02, -2.0272e-02, -1.1678e-02],\n",
      "          [-7.7072e-03, -3.2931e-02, -5.5725e-02, -3.5079e-02, -1.5041e-02],\n",
      "          [-1.2799e-02, -3.5406e-02, -4.2039e-02, -1.6676e-02, -1.8310e-02],\n",
      "          [-3.9237e-03,  5.0447e-03, -2.2888e-03,  1.1537e-02,  1.1631e-02]],\n",
      "\n",
      "         [[ 1.8497e-02,  2.3962e-02,  1.8591e-02, -2.1020e-03,  3.0035e-02],\n",
      "          [-9.1552e-03, -2.0225e-02, -2.0879e-02, -1.5274e-02, -4.1105e-03],\n",
      "          [-2.5364e-02, -3.6107e-02,  1.1210e-02, -1.3966e-02,  1.0463e-02],\n",
      "          [-1.6816e-03, -1.7049e-02,  1.9852e-02,  6.1190e-03,  4.9513e-03],\n",
      "          [ 1.0603e-02,  1.2892e-02,  4.2506e-02,  1.5835e-02,  1.7049e-02]],\n",
      "\n",
      "         [[-3.9704e-03,  1.6068e-02,  8.7815e-03, -9.1085e-03,  2.2281e-02],\n",
      "          [-2.0926e-02, -3.9704e-03, -3.2183e-02, -2.1113e-02, -1.3079e-03],\n",
      "          [-4.2039e-03,  1.4901e-02,  3.7835e-03, -5.2315e-03,  9.8558e-03],\n",
      "          [ 1.2238e-02,  3.7368e-03, -3.4565e-03,  5.9789e-03,  1.4807e-02],\n",
      "          [ 1.3172e-02, -1.9618e-03,  2.0926e-02,  1.4013e-04, -8.3611e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.4460e-03, -3.2884e-02, -1.5695e-02, -1.7797e-02,  2.1020e-03],\n",
      "          [-5.4044e-02, -5.4698e-02, -4.5402e-02, -5.6239e-02, -3.6714e-02],\n",
      "          [ 2.8260e-02,  2.9521e-02,  4.4842e-02,  2.2047e-02,  3.5360e-02],\n",
      "          [ 1.6816e-02,  1.6535e-02,  5.4557e-02,  1.7049e-02,  2.3355e-02],\n",
      "          [-4.0638e-03, -8.0341e-03,  4.2039e-04,  7.4736e-03,  1.0883e-02]],\n",
      "\n",
      "         [[ 2.0646e-02,  2.0693e-02,  7.6558e-02,  2.9054e-02,  4.1525e-02],\n",
      "          [-9.8091e-04,  5.5351e-02,  1.3224e-01,  6.7963e-02,  4.1525e-02],\n",
      "          [-3.9237e-03,  3.5687e-02,  1.2873e-01,  6.1844e-02,  2.9334e-02],\n",
      "          [ 2.5971e-02,  3.8583e-02,  1.3247e-01,  3.2650e-02, -1.8030e-02],\n",
      "          [-1.9899e-02, -1.3873e-02, -1.0510e-02, -1.3639e-02, -2.4756e-03]],\n",
      "\n",
      "         [[ 7.0392e-02,  2.1487e-02, -9.1085e-03, -9.1085e-03, -5.6986e-03],\n",
      "          [ 3.0875e-02, -1.0089e-02, -5.8341e-02, -3.8769e-02, -2.0179e-02],\n",
      "          [-7.5670e-03, -4.3861e-02, -8.5620e-02, -5.4838e-02, -1.8731e-02],\n",
      "          [-5.6519e-03, -4.2460e-02, -7.0299e-02, -3.9470e-02,  2.8026e-03],\n",
      "          [ 4.9092e-02,  8.0809e-03, -2.0459e-02,  1.7002e-02,  2.4289e-02]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 2.4835e-02,  1.3093e-02,  2.8189e-02],\n",
      "          [ 4.2540e-02,  5.7334e-02, -6.0805e-03],\n",
      "          [-4.1702e-03,  9.2955e-03, -1.5423e-02]],\n",
      "\n",
      "         [[-3.8906e-03, -7.8581e-02, -5.1789e-02],\n",
      "          [ 2.6465e-02, -4.9856e-02, -1.7706e-03],\n",
      "          [ 8.2704e-03, -4.9320e-02,  3.1125e-02]],\n",
      "\n",
      "         [[ 1.6448e-02, -1.2138e-02,  1.7426e-02],\n",
      "          [ 5.1999e-02, -6.7095e-03,  2.7304e-02],\n",
      "          [ 7.5482e-03, -4.2401e-02, -2.7887e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6308e-04,  2.4089e-02,  3.6926e-02],\n",
      "          [-2.4136e-02, -3.5272e-02,  3.6809e-03],\n",
      "          [ 1.9523e-02, -3.0333e-02, -3.5248e-02]],\n",
      "\n",
      "         [[ 1.3233e-02, -1.8614e-02, -5.3327e-02],\n",
      "          [ 1.6308e-04, -1.4700e-02, -2.2808e-02],\n",
      "          [-6.7561e-03,  2.3274e-02,  1.3862e-02]],\n",
      "\n",
      "         [[ 3.0496e-02,  7.5715e-03,  4.8924e-04],\n",
      "          [-4.5662e-03, -1.2813e-02, -6.4999e-03],\n",
      "          [-9.8080e-03, -1.5562e-02,  1.9360e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3652e-02, -3.9162e-02,  2.0012e-02],\n",
      "          [ 5.7381e-02,  1.1928e-02,  2.3041e-02],\n",
      "          [-2.2225e-02, -1.8871e-02, -2.0921e-02]],\n",
      "\n",
      "         [[-1.3396e-02,  1.9383e-02,  2.0012e-02],\n",
      "          [ 2.2132e-03, -1.5306e-02, -2.0595e-02],\n",
      "          [ 5.2185e-02, -4.0700e-02, -1.6005e-02]],\n",
      "\n",
      "         [[ 8.2704e-03, -1.2301e-02, -2.6955e-02],\n",
      "          [ 2.5394e-03, -5.6845e-03, -5.1463e-02],\n",
      "          [-2.8818e-02, -8.5127e-02, -6.5884e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1509e-02,  2.4206e-02,  5.8243e-04],\n",
      "          [-3.3641e-02,  7.7486e-02, -1.8102e-02],\n",
      "          [ 2.2412e-02,  6.3391e-02, -1.0717e-03]],\n",
      "\n",
      "         [[-1.6890e-02,  5.7311e-03,  3.7625e-02],\n",
      "          [-1.6494e-02, -3.2383e-03,  3.6273e-02],\n",
      "          [ 3.2895e-02, -1.2301e-02,  1.4677e-03]],\n",
      "\n",
      "         [[ 5.8359e-02,  6.4975e-02,  6.6420e-02],\n",
      "          [-1.3978e-02, -2.4019e-02, -1.2114e-02],\n",
      "          [ 2.6326e-03, -1.4910e-02, -7.8977e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0841e-03,  9.6683e-03, -1.2580e-02],\n",
      "          [ 1.1672e-02,  4.7386e-02,  4.9436e-02],\n",
      "          [-1.1649e-02,  7.7276e-02,  2.3227e-02]],\n",
      "\n",
      "         [[ 9.5751e-03, -3.5039e-02, -1.5819e-02],\n",
      "          [-2.2668e-02,  1.6355e-02,  1.8708e-02],\n",
      "          [-1.7566e-02, -5.9873e-03, -1.2347e-02]],\n",
      "\n",
      "         [[-3.8906e-03, -5.0322e-03,  2.8422e-03],\n",
      "          [ 2.3670e-02,  3.0053e-03, -5.0345e-02],\n",
      "          [-3.0309e-02, -2.0897e-02, -9.9711e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3745e-02, -4.8458e-03,  3.4480e-03],\n",
      "          [-1.7240e-03,  9.8546e-03,  3.1684e-03],\n",
      "          [-1.5702e-02,  2.4066e-02,  4.3519e-02]],\n",
      "\n",
      "         [[ 1.7380e-02,  3.9628e-02,  5.0578e-02],\n",
      "          [-1.8078e-02,  2.3181e-02,  7.5063e-02],\n",
      "          [-1.4631e-02, -1.4677e-03,  2.4485e-02]],\n",
      "\n",
      "         [[-3.6343e-03,  1.6960e-02,  9.5052e-03],\n",
      "          [ 8.2937e-03,  3.0053e-03, -3.5877e-03],\n",
      "          [-1.8638e-04, -9.5518e-04, -7.6880e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1154e-02,  3.1008e-02, -5.1253e-04],\n",
      "          [-2.0012e-02, -9.5751e-03,  2.7258e-02],\n",
      "          [-9.7847e-03, -3.9139e-02,  9.2256e-03]],\n",
      "\n",
      "         [[-2.2878e-02, -6.1970e-03, -1.8218e-02],\n",
      "          [ 2.6093e-02,  1.8195e-02, -3.5668e-02],\n",
      "          [-1.9034e-02, -2.5557e-02, -3.2383e-03]],\n",
      "\n",
      "         [[ 4.4264e-04,  1.1439e-02,  3.0356e-02],\n",
      "          [ 2.1317e-02,  1.1392e-02,  1.3372e-02],\n",
      "          [ 2.2482e-02, -1.0251e-02, -5.8243e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7351e-02,  1.4304e-02,  1.8847e-02],\n",
      "          [ 3.9162e-02, -4.1818e-02, -1.2580e-03],\n",
      "          [-2.4951e-02, -6.0200e-02,  1.1089e-02]],\n",
      "\n",
      "         [[ 1.3256e-02,  2.8236e-02, -2.0571e-02],\n",
      "          [ 1.2604e-02,  5.3770e-02, -2.9168e-02],\n",
      "          [ 4.3705e-02,  1.5516e-02, -3.4596e-02]],\n",
      "\n",
      "         [[-1.4304e-02, -1.1625e-02, -8.0375e-03],\n",
      "          [-1.7449e-02,  9.4819e-03, -3.2616e-04],\n",
      "          [-4.5895e-03,  2.4345e-02,  2.9494e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3017e-02,  3.7741e-02, -7.9210e-03],\n",
      "          [ 2.3320e-02, -3.2360e-02, -4.1352e-02],\n",
      "          [ 6.4812e-02,  2.6349e-02,  4.9110e-02]],\n",
      "\n",
      "         [[ 4.7969e-02, -2.4835e-02,  1.2161e-02],\n",
      "          [-2.7327e-02,  3.9419e-02, -1.8754e-02],\n",
      "          [-5.8825e-02,  2.6046e-02,  1.4677e-03]],\n",
      "\n",
      "         [[ 8.5966e-03, -2.6885e-02,  1.1509e-02],\n",
      "          [ 5.6146e-02, -1.3279e-02, -7.1755e-03],\n",
      "          [ 1.1183e-03, -4.7433e-02, -3.6017e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5621e-02, -8.5034e-03,  6.2226e-02],\n",
      "          [ 1.0950e-02,  1.9733e-02,  4.8225e-02],\n",
      "          [-1.1532e-02,  4.3332e-03,  5.2931e-02]],\n",
      "\n",
      "         [[-1.0717e-03,  2.2901e-02,  2.1992e-02],\n",
      "          [ 1.3279e-02,  4.9343e-02,  1.2208e-02],\n",
      "          [ 1.0507e-02,  1.7310e-02, -1.7985e-02]],\n",
      "\n",
      "         [[-2.6675e-02, -1.8055e-02, -2.4811e-02],\n",
      "          [-3.3920e-02, -1.4677e-03, -1.1159e-02],\n",
      "          [-1.3209e-02, -4.5895e-03,  3.0286e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0805e-03, -2.5068e-02, -4.7666e-02],\n",
      "          [ 2.3996e-02,  5.2558e-02, -2.1783e-02],\n",
      "          [ 2.5603e-02,  1.1881e-02, -2.4462e-03]],\n",
      "\n",
      "         [[ 2.5277e-02, -2.8539e-02,  8.4801e-03],\n",
      "          [ 6.8726e-03, -8.9228e-03,  3.4480e-03],\n",
      "          [ 2.7700e-02,  1.2907e-02,  1.2068e-02]],\n",
      "\n",
      "         [[ 2.8166e-02,  1.3559e-02,  6.9961e-02],\n",
      "          [ 2.7793e-02, -3.6926e-02,  1.0926e-01],\n",
      "          [ 2.3204e-02, -3.4573e-02, -4.8807e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2616e-04,  1.7449e-02, -9.6683e-03],\n",
      "          [ 9.2023e-03,  1.5050e-02,  8.6432e-03],\n",
      "          [-1.8847e-02, -2.1457e-02, -1.5096e-02]],\n",
      "\n",
      "         [[ 4.3915e-02, -4.6594e-05, -7.7113e-03],\n",
      "          [-8.0375e-03, -3.4410e-02, -2.2202e-02],\n",
      "          [-1.4095e-02, -2.7887e-02, -2.4625e-02]],\n",
      "\n",
      "         [[-2.6279e-02,  1.1649e-02, -1.6238e-02],\n",
      "          [-5.7753e-02, -5.8359e-02, -4.8295e-02],\n",
      "          [-4.1678e-02, -6.6233e-02, -5.7614e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-1.9641e-03, -8.1419e-03, -1.1357e-02],\n",
      "          [-1.9323e-02,  7.0226e-04,  1.1423e-02],\n",
      "          [-5.4074e-02, -1.1521e-03, -2.4426e-02]],\n",
      "\n",
      "         [[ 3.4992e-02,  1.3321e-02,  2.6028e-02],\n",
      "          [-2.8156e-02, -6.2326e-03, -2.6873e-02],\n",
      "          [ 3.4455e-03,  1.8138e-02,  1.4660e-02]],\n",
      "\n",
      "         [[-5.7245e-02, -4.7414e-02,  1.8544e-03],\n",
      "          [-4.0161e-02, -4.6207e-02, -2.5655e-02],\n",
      "          [-5.1441e-02, -4.8972e-02,  2.5347e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8434e-02, -2.3361e-02,  9.7000e-03],\n",
      "          [-4.4308e-02, -7.6152e-03, -1.7831e-02],\n",
      "          [-5.1803e-02, -3.5124e-02, -4.5526e-02]],\n",
      "\n",
      "         [[-3.6540e-03, -1.1302e-03, -4.4670e-02],\n",
      "          [-5.2406e-02, -3.1755e-02, -5.2395e-02],\n",
      "          [-3.1163e-03, -1.1094e-02, -4.4254e-02]],\n",
      "\n",
      "         [[-1.9872e-02, -1.5252e-03,  1.5889e-02],\n",
      "          [ 5.0695e-03, -1.4868e-02, -2.3679e-02],\n",
      "          [ 2.5874e-02,  3.3193e-02,  8.0650e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1035e-02,  2.1375e-02,  5.2779e-02],\n",
      "          [-5.6291e-03,  2.3965e-02,  3.3774e-02],\n",
      "          [-9.1404e-03,  3.4279e-02,  2.3592e-02]],\n",
      "\n",
      "         [[-2.3855e-02, -1.8325e-02, -8.2626e-03],\n",
      "          [ 3.1602e-02,  1.3639e-02,  4.5285e-02],\n",
      "          [-3.5651e-02,  2.4656e-02,  1.0095e-02]],\n",
      "\n",
      "         [[ 1.3387e-03,  3.9700e-02,  2.5347e-02],\n",
      "          [ 3.0779e-02,  1.1346e-02, -3.0943e-03],\n",
      "          [-2.8036e-02,  2.2714e-03, -1.8369e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9488e-02, -4.1587e-03, -1.7908e-02],\n",
      "          [ 1.9192e-02,  2.6510e-02,  2.5457e-03],\n",
      "          [ 1.3738e-02, -1.0161e-02,  8.5479e-03]],\n",
      "\n",
      "         [[ 2.7520e-02,  2.5600e-02,  2.5161e-02],\n",
      "          [-1.0238e-02, -2.6291e-02, -1.2180e-02],\n",
      "          [-3.3972e-02,  6.6825e-03,  3.8493e-02]],\n",
      "\n",
      "         [[-2.1617e-03,  2.1715e-02,  1.1236e-02],\n",
      "          [ 1.2224e-02, -2.1035e-02,  7.5274e-03],\n",
      "          [-2.8200e-03, -5.2121e-03, -1.2761e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2853e-02, -2.4799e-02, -1.8467e-02],\n",
      "          [-5.4096e-03,  6.1119e-03,  1.2564e-02],\n",
      "          [ 4.7743e-02,  1.8786e-02,  4.1280e-02]],\n",
      "\n",
      "         [[-7.3628e-03, -1.5691e-03,  2.6115e-03],\n",
      "          [ 4.6744e-03, -4.8171e-03,  7.7907e-03],\n",
      "          [-6.7703e-03,  2.7652e-03,  1.4309e-02]],\n",
      "\n",
      "         [[ 4.7183e-04, -2.2780e-02, -2.7103e-03],\n",
      "          [-1.5208e-02, -2.4854e-02,  2.3482e-02],\n",
      "          [ 5.2450e-03, -2.0464e-02,  6.4641e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5223e-02, -1.4923e-02,  1.7085e-02],\n",
      "          [-2.3372e-03, -8.3833e-03, -9.7658e-04],\n",
      "          [-2.0925e-02,  3.6759e-03, -2.2264e-02]],\n",
      "\n",
      "         [[-4.1697e-03, -4.7293e-03, -9.9743e-03],\n",
      "          [-6.9348e-03, -2.8112e-02, -3.8668e-02],\n",
      "          [ 4.7842e-03,  3.3325e-02,  1.1379e-02]],\n",
      "\n",
      "         [[-4.2147e-02,  1.9751e-04, -3.4740e-02],\n",
      "          [-1.0973e-04,  1.3497e-03, -9.2282e-03],\n",
      "          [ 7.1883e-02,  5.0234e-02,  5.7333e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.1038e-02,  3.8471e-02,  1.6273e-02],\n",
      "          [ 7.2860e-03, -1.7557e-02, -4.6207e-02],\n",
      "          [-2.0124e-02, -2.6280e-02, -4.7337e-02]],\n",
      "\n",
      "         [[ 1.2926e-02,  2.2725e-02,  2.5172e-02],\n",
      "          [ 1.4473e-02,  2.5435e-02,  2.9989e-02],\n",
      "          [-2.4469e-03,  1.5143e-02,  1.1192e-02]],\n",
      "\n",
      "         [[-1.9927e-02, -1.1269e-02, -1.0435e-02],\n",
      "          [ 1.2674e-02,  1.2849e-02,  7.3189e-03],\n",
      "          [ 1.6053e-02,  5.4645e-03, -6.2984e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0186e-02,  5.0475e-03, -1.1631e-03],\n",
      "          [ 2.0805e-02,  3.2919e-04, -1.8665e-02],\n",
      "          [-1.4418e-02, -3.5662e-02, -1.7447e-02]],\n",
      "\n",
      "         [[ 5.9912e-02,  8.5369e-03,  7.4945e-03],\n",
      "          [ 6.1009e-02,  1.6953e-02, -3.3676e-02],\n",
      "          [ 1.1927e-02,  2.5051e-02, -1.4890e-02]],\n",
      "\n",
      "         [[-4.5504e-02, -5.0420e-02, -4.0962e-02],\n",
      "          [-1.9971e-02, -2.8134e-02, -1.9345e-02],\n",
      "          [-1.7787e-02, -2.2505e-02, -4.6810e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6810e-03, -2.4941e-02,  1.5592e-02],\n",
      "          [-2.4897e-02,  4.3123e-03,  4.9444e-02],\n",
      "          [ 4.5428e-03,  4.5493e-02,  4.5482e-02]],\n",
      "\n",
      "         [[ 1.0512e-02,  2.4689e-02, -5.7278e-03],\n",
      "          [ 4.6119e-02,  3.0516e-02,  3.4927e-02],\n",
      "          [-3.5355e-02,  4.2213e-02, -2.5347e-03]],\n",
      "\n",
      "         [[ 2.4711e-02,  3.6397e-02,  6.1448e-04],\n",
      "          [-2.2055e-03, -2.0388e-02, -1.0424e-03],\n",
      "          [-1.8917e-02, -2.0673e-02, -2.5391e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2323e-02, -3.4158e-02, -3.5113e-04],\n",
      "          [-6.7044e-03, -2.4524e-02, -8.1419e-03],\n",
      "          [-1.2224e-02,  1.3288e-02,  1.3848e-02]],\n",
      "\n",
      "         [[ 9.8317e-03,  2.5929e-02,  1.7974e-02],\n",
      "          [ 3.7560e-02,  4.7172e-02,  3.4235e-03],\n",
      "          [ 2.3866e-02, -1.8544e-03, -1.2805e-02]],\n",
      "\n",
      "         [[ 8.7234e-03,  2.9221e-02, -7.5054e-03],\n",
      "          [ 3.0943e-03, -1.1785e-02, -1.5823e-02],\n",
      "          [-1.2794e-02, -5.2384e-02,  3.5662e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9378e-04,  4.8083e-02,  2.7904e-02],\n",
      "          [ 6.0351e-04, -2.9407e-02, -8.9758e-03],\n",
      "          [ 9.5135e-03,  2.7542e-03,  1.5746e-02]],\n",
      "\n",
      "         [[ 1.6558e-02,  3.2765e-02,  1.8204e-02],\n",
      "          [-5.4755e-03,  2.7487e-02,  1.1906e-02],\n",
      "          [-5.4074e-02, -1.8950e-02, -3.8581e-02]],\n",
      "\n",
      "         [[-3.8646e-02, -3.5300e-02,  1.4254e-02],\n",
      "          [-5.7651e-02, -4.8303e-02,  2.8924e-02],\n",
      "          [-3.6079e-02,  3.1492e-03,  6.1843e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3310e-02,  2.5940e-02,  4.9883e-02],\n",
      "          [ 3.3357e-03, -4.9970e-02,  8.9977e-04],\n",
      "          [ 1.5307e-02,  1.8445e-02,  9.8756e-05]],\n",
      "\n",
      "         [[-3.2348e-02, -1.6284e-02,  2.3679e-02],\n",
      "          [-1.1521e-03, -1.3661e-02,  3.6869e-03],\n",
      "          [-2.3581e-02,  4.0929e-03,  3.6309e-02]],\n",
      "\n",
      "         [[-2.9308e-02, -1.7546e-02, -2.6829e-02],\n",
      "          [-3.4126e-02,  4.5954e-02, -1.1247e-02],\n",
      "          [ 2.6335e-04,  7.0051e-02,  6.7703e-03]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 4.5001e-03, -7.7337e-03, -1.5003e-02],\n",
      "          [-3.0281e-02, -4.4112e-02, -1.7562e-02],\n",
      "          [-1.4329e-02, -3.6708e-02, -5.2000e-02]],\n",
      "\n",
      "         [[ 3.3319e-02,  9.8220e-03, -6.4672e-03],\n",
      "          [ 1.4187e-02,  2.4333e-02,  3.1036e-02],\n",
      "          [-1.9435e-02,  1.9583e-02, -1.6538e-02]],\n",
      "\n",
      "         [[ 2.6947e-05, -6.3325e-04,  1.5420e-02],\n",
      "          [ 1.1257e-02,  5.7262e-04,  1.7455e-02],\n",
      "          [ 7.1206e-03,  1.0711e-03,  2.1854e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6801e-02, -2.1510e-02, -1.0698e-02],\n",
      "          [-1.0698e-02, -5.3839e-02, -1.9334e-02],\n",
      "          [ 1.6289e-02,  4.4462e-04,  6.0630e-05]],\n",
      "\n",
      "         [[ 1.2059e-03,  1.1924e-03, -1.7044e-03],\n",
      "          [-1.7239e-02, -2.7674e-02,  1.3473e-05],\n",
      "          [ 5.1872e-04, -1.6235e-03, -4.3923e-03]],\n",
      "\n",
      "         [[ 1.9887e-02,  2.9331e-02,  2.0877e-02],\n",
      "          [ 1.3520e-02,  3.1602e-02,  1.2847e-02],\n",
      "          [ 5.2748e-03,  1.2335e-02,  7.5383e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4208e-02,  2.3174e-03, -2.5107e-02],\n",
      "          [-7.6057e-03,  9.4852e-03, -4.6483e-03],\n",
      "          [ 1.3251e-02,  1.1506e-02, -1.4012e-02]],\n",
      "\n",
      "         [[ 2.1793e-02,  1.0758e-02,  1.1627e-02],\n",
      "          [ 4.1080e-02, -7.8078e-03,  1.9051e-02],\n",
      "          [ 6.6558e-02,  3.6654e-02,  2.0143e-03]],\n",
      "\n",
      "         [[-1.8701e-02, -4.9238e-02, -2.9176e-02],\n",
      "          [-1.5986e-02,  1.6168e-04,  4.5809e-03],\n",
      "          [-6.2247e-03,  4.1228e-03,  8.5151e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8009e-02, -7.3349e-02, -6.5628e-02],\n",
      "          [-5.9599e-02, -5.7511e-02, -4.2394e-02],\n",
      "          [-5.5820e-02, -6.3870e-02, -6.0623e-02]],\n",
      "\n",
      "         [[-3.6688e-02, -3.2969e-02, -1.0273e-02],\n",
      "          [-3.1831e-02, -5.3893e-03, -3.2262e-02],\n",
      "          [-3.2713e-02, -3.3144e-02, -2.8611e-02]],\n",
      "\n",
      "         [[-8.2591e-03, -2.5404e-02, -1.7785e-02],\n",
      "          [-1.1398e-02, -2.3383e-02, -1.1681e-02],\n",
      "          [-2.2676e-02, -3.1898e-02, -7.9627e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8229e-02, -2.9938e-02, -3.0914e-02],\n",
      "          [ 6.0630e-04, -4.5203e-02, -4.3788e-03],\n",
      "          [-6.0428e-03, -6.1842e-02, -1.4538e-02]],\n",
      "\n",
      "         [[ 1.3110e-02,  1.5973e-02, -5.2815e-03],\n",
      "          [-1.2692e-02,  1.2395e-03,  2.2467e-02],\n",
      "          [ 2.1079e-02, -6.7434e-03,  1.9617e-02]],\n",
      "\n",
      "         [[ 3.0894e-02, -3.0813e-02,  5.1535e-03],\n",
      "          [-5.6588e-04, -1.2510e-02,  2.3464e-02],\n",
      "          [ 2.5363e-02,  3.1076e-02,  2.8806e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0042e-02, -3.3690e-02, -3.3582e-02],\n",
      "          [-3.1218e-02, -4.3829e-02, -2.9783e-02],\n",
      "          [-5.5382e-02, -6.6673e-02, -5.1232e-02]],\n",
      "\n",
      "         [[-1.8425e-02, -1.0482e-02, -1.3096e-02],\n",
      "          [ 5.6520e-03, -2.6603e-02,  2.3982e-03],\n",
      "          [-2.3949e-02,  8.9328e-03,  3.3818e-03]],\n",
      "\n",
      "         [[ 5.6992e-03, -1.4834e-02,  1.3473e-03],\n",
      "          [-5.6588e-04,  6.3325e-03,  5.1737e-03],\n",
      "          [ 5.5510e-03, -1.4888e-03, -2.3524e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8687e-02, -5.8541e-03,  7.5855e-03],\n",
      "          [ 5.4702e-03, -5.1845e-02,  5.3017e-03],\n",
      "          [ 5.4270e-02, -3.1460e-03, -5.8474e-03]],\n",
      "\n",
      "         [[ 1.0684e-02, -1.6323e-02,  2.0675e-02],\n",
      "          [ 1.9334e-03, -3.2632e-02,  9.5660e-04],\n",
      "          [ 2.1625e-03,  2.7445e-02,  5.5059e-02]],\n",
      "\n",
      "         [[ 5.0727e-03, -2.6408e-02,  1.8580e-02],\n",
      "          [-2.5801e-03,  1.2328e-03,  4.8908e-03],\n",
      "          [ 5.3220e-04, -8.6229e-03, -2.3598e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3444e-02,  9.6401e-03,  1.7825e-02],\n",
      "          [-1.8330e-02, -5.7181e-02, -2.1025e-02],\n",
      "          [ 1.0186e-02, -3.0167e-02, -8.0166e-03]],\n",
      "\n",
      "         [[ 1.7623e-02,  2.5000e-02, -4.5708e-02],\n",
      "          [ 2.5249e-02,  3.9403e-02,  3.0032e-02],\n",
      "          [ 1.6262e-02,  5.3017e-02,  8.1109e-03]],\n",
      "\n",
      "         [[ 4.1767e-03,  8.5151e-03,  3.5233e-03],\n",
      "          [ 2.7546e-02,  4.5621e-02,  3.8399e-03],\n",
      "          [ 2.1281e-02,  2.0102e-02,  1.6168e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4133e-02, -3.3218e-02, -5.2883e-03],\n",
      "          [-8.9463e-03, -3.3259e-02,  4.3249e-03],\n",
      "          [ 1.7091e-02, -2.8523e-02, -2.5047e-02]],\n",
      "\n",
      "         [[-1.4275e-02, -2.7398e-02,  1.1634e-02],\n",
      "          [-2.2797e-02, -3.2013e-02, -9.8220e-03],\n",
      "          [-2.0385e-02, -3.1689e-02, -9.8153e-03]],\n",
      "\n",
      "         [[-2.0244e-02, -7.1880e-03,  5.0592e-03],\n",
      "          [ 9.2898e-03, -1.4389e-02, -2.8597e-02],\n",
      "          [ 1.5562e-03, -1.7381e-02, -7.2688e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4868e-02, -9.5728e-03,  2.7290e-02],\n",
      "          [ 1.7650e-03, -1.8438e-02,  7.5855e-03],\n",
      "          [-6.8040e-03, -1.3877e-03,  3.8668e-03]],\n",
      "\n",
      "         [[-2.7930e-02, -3.4296e-02, -1.5764e-02],\n",
      "          [-1.5905e-02, -4.4206e-02, -1.5326e-02],\n",
      "          [-1.9253e-02, -2.3012e-02,  7.2082e-04]],\n",
      "\n",
      "         [[-3.6863e-02,  1.5528e-02, -7.3429e-04],\n",
      "          [-3.2336e-03, -2.5559e-02, -6.1977e-04],\n",
      "          [-7.5787e-03, -1.7273e-02, -1.2106e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0652e-03, -3.1069e-02,  4.9178e-04],\n",
      "          [ 1.3615e-02,  6.6625e-03, -1.3056e-02],\n",
      "          [-1.5804e-02,  9.5593e-03, -2.8361e-02]],\n",
      "\n",
      "         [[-1.5616e-02,  1.0866e-02, -4.3909e-02],\n",
      "          [-6.0360e-03,  4.7035e-02, -6.7703e-03],\n",
      "          [ 2.3875e-02,  1.5272e-02,  2.1207e-02]],\n",
      "\n",
      "         [[-3.4364e-02, -2.7351e-03, -4.0332e-02],\n",
      "          [-2.1268e-02, -2.4036e-02, -2.0257e-02],\n",
      "          [-7.9425e-03, -1.4821e-03, -6.8175e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0058e-02, -2.2871e-02, -5.4971e-03],\n",
      "          [ 3.2437e-02, -1.3507e-02,  2.5936e-03],\n",
      "          [-2.8321e-02, -3.6304e-02, -1.9826e-02]],\n",
      "\n",
      "         [[-9.0338e-03,  1.6565e-02,  5.8609e-04],\n",
      "          [-7.4103e-04,  3.3367e-02,  2.2972e-02],\n",
      "          [ 1.0570e-02,  8.1446e-03, -3.4815e-02]],\n",
      "\n",
      "         [[ 7.4777e-03,  1.9469e-03,  8.8991e-03],\n",
      "          [-7.3093e-03, -2.9486e-02,  1.1991e-03],\n",
      "          [ 8.8654e-03,  1.1836e-02,  7.4777e-04]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0029,  0.0072,  0.0137,  ..., -0.0002, -0.0030, -0.0114],\n",
      "        [ 0.0023, -0.0004, -0.0011,  ...,  0.0057,  0.0004, -0.0123],\n",
      "        [-0.0185, -0.0145, -0.0198,  ..., -0.0003, -0.0012,  0.0191],\n",
      "        ...,\n",
      "        [-0.0063,  0.0026, -0.0084,  ..., -0.0079,  0.0055,  0.0067],\n",
      "        [-0.0101, -0.0038, -0.0079,  ..., -0.0066, -0.0057, -0.0098],\n",
      "        [ 0.0026, -0.0158, -0.0027,  ...,  0.0056,  0.0061, -0.0032]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0048,  0.0024,  0.0031,  ..., -0.0143,  0.0102, -0.0044],\n",
      "        [-0.0120, -0.0122,  0.0048,  ..., -0.0135, -0.0004,  0.0107],\n",
      "        [ 0.0114, -0.0114,  0.0067,  ..., -0.0079, -0.0124, -0.0142],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0099, -0.0038,  ...,  0.0118,  0.0059, -0.0136],\n",
      "        [ 0.0256,  0.0130,  0.0081,  ...,  0.0021, -0.0035, -0.0146],\n",
      "        [ 0.0037,  0.0066, -0.0137,  ..., -0.0088, -0.0041, -0.0026]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0500, -0.0294,  0.0189,  ..., -0.0471, -0.1147,  0.0169],\n",
      "        [-0.0989,  0.0067, -0.0265,  ...,  0.0384, -0.0606,  0.0068],\n",
      "        [-0.0850,  0.0199,  0.0370,  ..., -0.0133,  0.0117,  0.0034],\n",
      "        ...,\n",
      "        [-0.0435, -0.0207,  0.0522,  ..., -0.0105, -0.0985,  0.0074],\n",
      "        [ 0.1859,  0.0055, -0.0489,  ..., -0.0247, -0.0554,  0.0216],\n",
      "        [-0.0974,  0.0109,  0.0018,  ...,  0.0233, -0.0073, -0.0061]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for layer in [*alexnet.features,*alexnet.classifier]:\n",
    "    try:\n",
    "        layer.weight = nn.parameter.Parameter(quantize_requantize(layer.weight.detach(), torch.float32, torch.int8))\n",
    "        print(layer.weight)\n",
    "    except (TypeError, AttributeError):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5880d742-ee2d-4628-a8c0-57da71e62830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "alexnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d087bfe-559b-4fb4-b64b-289e6a2e07d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "#Testing Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae55af9-fe8e-4616-90ee-4843cd771d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2b1d956-737b-4bc0-8d4f-2b7800db1c8d",
   "metadata": {},
   "source": [
    "# Row-wise quantization\n",
    "If you ran the per tensor quantization, you should re-initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5727bbbe-420a-4173-b3d7-ec25769a1150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float128'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m---> 12\u001b[0m             weights[\u001b[38;5;28mfilter\u001b[39m,channel,row] \u001b[38;5;241m=\u001b[39m \u001b[43mquantize_requantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# for row in range(0,weights.shape[2]):\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m#     weights[filter,channel, row] = quantize_dequantize_dt(weights[filter,channel,row])\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# print(f'Finish window')\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# layer.weight = nn.parameter.Parameter(weights)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights shape post-quantization: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWeights: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[95], line 13\u001b[0m, in \u001b[0;36mquantize_requantize\u001b[1;34m(mat, initial_dt, target_dt)\u001b[0m\n\u001b[0;32m     11\u001b[0m i_bounds \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mmin(mat), torch\u001b[38;5;241m.\u001b[39mmax(mat))\n\u001b[0;32m     12\u001b[0m t_bounds \u001b[38;5;241m=\u001b[39m get_minmax(target_dt)\n\u001b[1;32m---> 13\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat128\u001b[49m(t_bounds[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m t_bounds[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat128(i_bounds[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m i_bounds[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(S)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# mat.apply_(lambda x: (x * S))\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cs190-project\\lib\\site-packages\\numpy\\__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float128'"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for layer in [*alexnet.features,*alexnet.classifier]:\n",
    "    count += 1\n",
    "    # try:\n",
    "    if len(layer.weight.shape) == 4:\n",
    "        weights = layer.weight.detach()\n",
    "        print(f'Layer {count}')# weights shape pre-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "        for filter in range(0, weights.shape[0]):\n",
    "            # print(f'Filter num {filter}')\n",
    "            for channel in range(0, weights.shape[1]):\n",
    "                for row in range(0, weights.shape[2]):\n",
    "                    weights[filter,channel,row] = quantize_requantize(weights[filter,channel,row], torch.float32, torch.int8)\n",
    "                # for row in range(0,weights.shape[2]):\n",
    "                #     weights[filter,channel, row] = quantize_dequantize_dt(weights[filter,channel,row])\n",
    "                # print(f'Finish window')\n",
    "        # print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "        # layer.weight = nn.parameter.Parameter(weights)\n",
    "        print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "        layer.weight = nn.parameter.Parameter(weights)\n",
    "    else:\n",
    "        weights = layer.weight.detach()\n",
    "        print(f'Layer {count}')# weights shape pre-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "        for row in range(0, weights.shape[0]):\n",
    "            weights[row] = quantize_requantize(weights[row], torch.float32, torch.int8)\n",
    "        # for row in tqdm(range(0,weights.shape[0])):\n",
    "        #     weights[row] = quantize_dequantize_dt(weights[row])\n",
    "        layer.weight = nn.parameter.Parameter(weights)\n",
    "        # print(f'Layer {count} weights shape post-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "        # print(layer.weight)\n",
    "    # except (TypeError, AttributeError):\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2296380-c6ee-4dfa-8636-8f2749e90280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiating CUDA device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Verifying CUDA\n",
    "print(device)\n",
    "\n",
    "#Move the input and alexnet to GPU for speed if available\n",
    "alexnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67d1b406-b710-428e-9fa2-e8c7b0c4dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "#Testing Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ccba45-4a7d-415b-b018-1fc8ada8295c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6222a-2331-4f5d-b8b5-12759c3fbc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf9e8fb4-07f1-461f-b9e2-b6d662f5a436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[  0.,   0.,   3.,  -2.,   0.],\n",
       "          [  1.,   0.,   7.,  -6.,   0.],\n",
       "          [  1.,  -8.,   1.,  -6.,   1.],\n",
       "          [ -1.,  -4.,  -3.,   0.,  -1.],\n",
       "          [ -2.,   0.,   2.,   0.,  -1.]],\n",
       "\n",
       "         [[  0.,  -1.,  -3.,   0.,   0.],\n",
       "          [ -1.,   1.,   0.,   0.,   0.],\n",
       "          [ -2.,   3.,   0.,  -1.,   0.],\n",
       "          [ -4.,   0.,   1.,  -1.,   0.],\n",
       "          [  0.,  -2.,  -1.,  -1.,   1.]],\n",
       "\n",
       "         [[ -1.,  -5.,  -7.,   2.,   4.],\n",
       "          [ -1.,  -8.,  -2.,   3.,   3.],\n",
       "          [ -1.,   2.,  15.,   3.,  -4.],\n",
       "          [  1.,   8.,   2., -10.,  -3.],\n",
       "          [  3.,   4.,   0.,  -6.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -1.,   1.,   2.,  -1.,   0.],\n",
       "          [ -1.,   1.,   6.,  -3.,  -4.],\n",
       "          [ -3.,  -6.,   7.,   0.,  -5.],\n",
       "          [  0.,   2.,   4.,   3.,  -1.],\n",
       "          [  0.,   0.,  -2.,  -1.,  -1.]],\n",
       "\n",
       "         [[ -2.,  -3.,   3.,   1.,  -5.],\n",
       "          [ -2.,  -4.,   6.,   2.,   1.],\n",
       "          [  0.,  -1.,  -5.,  -6.,   0.],\n",
       "          [ -2.,   5.,   5.,   1.,  -3.],\n",
       "          [ -5.,   0.,   7.,   1.,  -6.]],\n",
       "\n",
       "         [[  0.,   0.,  -3.,  -6.,   2.],\n",
       "          [  2.,   1.,  10., -11.,  -8.],\n",
       "          [  0., -10.,  17.,  13., -11.],\n",
       "          [  1.,  -5., -10.,   8.,   2.],\n",
       "          [  3.,   5.,  -3.,   0.,   1.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,  -3.,   1.,  -1.,   0.],\n",
       "          [  1.,  -5.,  -6.,  -6.,  -1.],\n",
       "          [  0.,  -3., -17.,  -4.,  -3.],\n",
       "          [ -3.,   1.,  -7.,  -1.,  -1.],\n",
       "          [  0.,   0.,  -4.,  -1.,  -1.]],\n",
       "\n",
       "         [[  3.,   2.,  -4.,   1.,  -2.],\n",
       "          [  1.,   4.,  -5.,  -1.,  -3.],\n",
       "          [ -2.,   3.,   0.,  -1.,   0.],\n",
       "          [ -2.,  -5.,  -1.,   0.,  -2.],\n",
       "          [ -1.,  -7.,   0.,   1.,  -1.]],\n",
       "\n",
       "         [[ -1.,  12.,   4.,  -1.,   0.],\n",
       "          [ -7.,  14.,  15.,   1.,   0.],\n",
       "          [ -8.,   8.,  28.,   4.,   3.],\n",
       "          [ -3.,  -6.,  18.,   7.,   0.],\n",
       "          [ -1., -14.,   7.,  11.,   2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  0.,   0.,   0.,  -1.,  -3.],\n",
       "          [  0.,   2.,   0.,   1.,  -2.],\n",
       "          [  0.,   4.,   0.,   2.,   0.],\n",
       "          [ -3.,   3.,   3.,  -1.,   0.],\n",
       "          [ -3.,  -2.,   2.,  -2.,  -2.]],\n",
       "\n",
       "         [[  6.,   3.,  -4.,   1.,   0.],\n",
       "          [  2.,   4.,  -5.,   2.,   2.],\n",
       "          [ -5.,  -3.,  -4.,  -6.,  -1.],\n",
       "          [-11.,  -4.,   1.,  -4.,  -7.],\n",
       "          [ -6.,  -1.,   1.,  -2.,  -4.]],\n",
       "\n",
       "         [[  0.,   0.,   1.,   0.,   0.],\n",
       "          [  0.,   2.,  -2.,   1.,   0.],\n",
       "          [  0.,   5.,  -2.,   3.,   2.],\n",
       "          [ -1.,   2.,   2.,   0.,   0.],\n",
       "          [  0.,   1.,   3.,  -2.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,  -3.,  -5.,  -2.,   0.],\n",
       "          [ 11.,  -5.,  -5.,  -3.,   0.],\n",
       "          [  1.,  -3.,  -3.,  -1.,   1.],\n",
       "          [  1.,   0.,  -1.,  -1.,  -1.],\n",
       "          [  3.,   1.,   1.,   0.,  -2.]],\n",
       "\n",
       "         [[  3.,  -1.,  -2.,  -2.,   0.],\n",
       "          [  5.,  -6.,  -5.,  -5.,   0.],\n",
       "          [  6.,  -5.,  -6.,  -5.,  -1.],\n",
       "          [  5.,  -3.,  -6.,  -4.,  -1.],\n",
       "          [  6.,   1.,  -1.,  -1.,   1.]],\n",
       "\n",
       "         [[  0.,   0.,  -2.,  -2.,  -2.],\n",
       "          [ 14.,   0.,  -2.,  -2.,  -2.],\n",
       "          [  8.,   0.,  -3.,  -2.,   0.],\n",
       "          [ -3.,  -1.,  -2.,   0.,   0.],\n",
       "          [ -2.,   0.,   0.,  -1.,  -1.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  1.,   0.,  -1.,  -1.,   0.],\n",
       "          [ 12.,   1.,   0.,   0.,   0.],\n",
       "          [  5.,   0.,  -2.,   0.,   0.],\n",
       "          [  1.,   0.,   0.,   0.,   0.],\n",
       "          [  2.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  1.,  -2.,  -2.,  -2.,   0.],\n",
       "          [ 15.,  -7.,  -4.,   0.,   0.],\n",
       "          [  2.,  -8.,  -7.,  -1.,   0.],\n",
       "          [  0.,  -2.,  -2.,  -1.,   2.],\n",
       "          [ -1.,  -4.,  -6.,  -2.,   0.]],\n",
       "\n",
       "         [[ -1.,   0.,   0.,  -1.,   0.],\n",
       "          [  4.,  -2.,   0.,   0.,   0.],\n",
       "          [  0.,  -4.,   0.,   0.,  -1.],\n",
       "          [ -1.,   0.,  -1.,   0.,   0.],\n",
       "          [  0.,   0.,  -1.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  2.,   1.,   3.,   0.,  -2.],\n",
       "          [ -1.,  -3.,   0.,  -2.,  -3.],\n",
       "          [ -2.,  -3.,  -4.,  -4.,  -2.],\n",
       "          [  0.,   0.,  -3.,  -4.,  -1.],\n",
       "          [  1.,   0.,   0.,  -1.,  -1.]],\n",
       "\n",
       "         [[  0.,   0.,  -3.,  -3.,  -1.],\n",
       "          [ -2.,   0.,   0.,   4.,   2.],\n",
       "          [ -1.,   0.,  -2.,  -2.,  -4.],\n",
       "          [  0.,   1.,  -2.,  -6.,  -6.],\n",
       "          [  0.,   3.,   1.,  -2.,  -3.]],\n",
       "\n",
       "         [[ -3.,  -4.,  -9.,  -3.,   5.],\n",
       "          [ -2.,  -3.,  -4.,   2.,   9.],\n",
       "          [  2.,   2.,   4.,   2.,   0.],\n",
       "          [  2.,   2.,   5.,   0.,  -4.],\n",
       "          [  0.,   1.,   4.,   3.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -1.,  -2.,  -2.,   4.,   1.],\n",
       "          [ -4.,  -5.,  -4.,   4.,   2.],\n",
       "          [  1.,   1.,  -2.,   1.,   2.],\n",
       "          [  0.,   0.,  -1.,  -1.,   2.],\n",
       "          [  0.,   0.,   0.,  -2.,   0.]],\n",
       "\n",
       "         [[ -5.,   0.,   0.,  -2.,   0.],\n",
       "          [ -5.,  -2.,  -4., -11.,  -5.],\n",
       "          [ -7.,  -1.,  -1.,   5.,  12.],\n",
       "          [ -2.,  -2.,  -4.,   2.,   6.],\n",
       "          [ -4.,  -1.,  -3.,   2.,   1.]],\n",
       "\n",
       "         [[  3.,   1.,  -2.,   0.,  -5.],\n",
       "          [  4.,   2.,  -4.,   1.,   6.],\n",
       "          [  3.,   2.,  -5.,  -8.,  -2.],\n",
       "          [  2.,   4.,   4.,   0.,  -4.],\n",
       "          [  0.,   2.,   3.,   1.,   0.]]],\n",
       "\n",
       "\n",
       "        [[[  2.,   0.,   1.,  -1.,  -2.],\n",
       "          [  0.,  -3.,  -5.,  -8.,  -5.],\n",
       "          [ -1.,  -1.,  -7.,  -9.,  -5.],\n",
       "          [  0.,   0.,  -4.,  -4.,  -3.],\n",
       "          [  1.,  -1.,  -3.,   0.,  -2.]],\n",
       "\n",
       "         [[  5.,   0., -15.,  -9.,  -2.],\n",
       "          [  9.,   9.,  -5.,  -8.,  -8.],\n",
       "          [ 12.,  15.,   3.,  -6., -16.],\n",
       "          [  5.,  10.,   6.,   0., -11.],\n",
       "          [  3.,   7.,   9.,   5.,  -6.]],\n",
       "\n",
       "         [[ -5.,  -3.,  -4.,  -2.,   5.],\n",
       "          [ -2.,  -2.,  -5.,  -3.,   0.],\n",
       "          [  1.,   2.,  -1.,  -7.,  -4.],\n",
       "          [ -3.,   0.,   1.,  -6.,  -8.],\n",
       "          [ -2.,  -1.,   0.,  -6.,  -9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -1.,  -2.,   0.,   1.,   0.],\n",
       "          [  0.,  -2.,  -4.,   1.,   2.],\n",
       "          [  0.,  -3.,  -7.,   0.,   7.],\n",
       "          [  0.,   0.,  -1.,  -1.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,   1.]],\n",
       "\n",
       "         [[  0.,  -8.,  -7.,  -1.,   5.],\n",
       "          [  6.,  -2., -18.,  -8.,  -2.],\n",
       "          [  8.,   5.,  -8., -15.,  -7.],\n",
       "          [  1.,   2.,   1.,  -7.,  -9.],\n",
       "          [  0.,  -2.,   1.,   0.,  -5.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,   2.,   0.],\n",
       "          [  0.,   0.,   0.,   1.,   1.],\n",
       "          [  2.,   0.,  -1.,   0.,   2.],\n",
       "          [  1.,   2.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,  -1.,  -1.]]],\n",
       "\n",
       "\n",
       "        [[[  0.,  -1.,  -1.,   0.,   0.],\n",
       "          [ -1.,  -3.,  -3.,  -2.,  -1.],\n",
       "          [ -1.,  -3.,  -5.,  -3.,  -1.],\n",
       "          [ -1.,  -3.,  -4.,  -1.,  -1.],\n",
       "          [  0.,   0.,  -1.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   1.,   1.,   0.,   2.],\n",
       "          [ -1.,  -2.,  -2.,  -1.,   0.],\n",
       "          [ -2.,  -3.,   0.,  -1.,   0.],\n",
       "          [  0.,  -1.,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   2.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  -1.,   1.],\n",
       "          [ -2.,   0.,  -2.,  -2.,   0.],\n",
       "          [ -1.,   0.,   0.,  -1.,   0.],\n",
       "          [  0.,   0.,  -1.,   0.,   0.],\n",
       "          [  0.,   0.,   0.,   0.,  -1.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  0.,  -2.,  -1.,  -1.,   0.],\n",
       "          [ -4.,  -4.,  -3.,  -4.,  -2.],\n",
       "          [  1.,   1.,   2.,   0.,   1.],\n",
       "          [  0.,   1.,   3.,   0.,   1.],\n",
       "          [  0.,   0.,   0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   1.,   4.,   0.,   1.],\n",
       "          [  0.,   3.,   8.,   3.,   1.],\n",
       "          [ -1.,   0.,   6.,   1.,   0.],\n",
       "          [  0.,   0.,   6.,   0.,  -3.],\n",
       "          [ -3.,  -3.,  -4.,  -3.,  -2.]],\n",
       "\n",
       "         [[  5.,   1.,   0.,   0.,   0.],\n",
       "          [  2.,   0.,  -4.,  -2.,  -1.],\n",
       "          [  0.,  -3.,  -6.,  -4.,  -1.],\n",
       "          [  0.,  -2.,  -5.,  -2.,   0.],\n",
       "          [  3.,   0.,  -1.,   1.,   1.]]]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alexnet.features[3].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa85eed-6efa-4b23-97dd-3750e7e74b2d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89116fd-eb0d-48c3-8b8c-70fb0bb65a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26469a11-223f-4be7-b312-862a336dac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ff6a4-133b-47ed-a4b6-19a719e7c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model(model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c418e2b-a9c2-4f3b-b0f9-c48867710a15",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.dtype' object has no attribute '__attributes__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__attributes__\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute '__attributes__'"
     ]
    }
   ],
   "source": [
    "torch.float32.__attributes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e5b1cff-9f50-4ee1-9cf2-5589a3c76220",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = [func for func in dir(torch.float32) if callable(getattr(torch.float32, func))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "817d128d-45b2-4a67-8666-c2da2ee0229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.iinfo(torch.int8).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ea9e3dd-53e9-4932-a08f-d3773b6a698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.dtype"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8cda26e5-a6c8-4470-b0bb-e39247eb822e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3045845854.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[163], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    I = (torch.eye(3) * 1000) @\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "I = (torch.eye(3) * 1000) @ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f207e953-dcf4-4a90-87a9-1e2b4fec3649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[884515., 876362., 208928.],\n",
       "        [504534.,  17749., 983694.],\n",
       "        [374258., 446598., 475318.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = (torch.rand((3,3)) * 1000000).round()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4d9fa78d-f607-45c3-9f6d-6f4bf9815542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003)\n",
      "tensor([[ -23,  -25,   55],\n",
      "        [-123,    4,    3],\n",
      "        [  98,  117,  125]], dtype=torch.int8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -87124.4531,  -94700.4844,  208341.0781],\n",
       "        [-465926.4062,   15152.0781,   11364.0586],\n",
       "        [ 371225.9062,  443198.2812,  473502.4375]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = quantize_requantize(r.clone().detach(),torch.float32, torch.int8)\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0e53ef28-6ec1-4ea1-bdaf-b5a3704ce02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[884515., 876362., 208928.],\n",
       "        [504534.,  17749., 983694.],\n",
       "        [374258., 446598., 475318.]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "89659b6c-eaea-470a-a705-59d758fbede8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1937e+11)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((qr - r)**2).mean(axis=None)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bb900b0e-ec11-41e0-a85d-67b0b0b1b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_path = 'model_{}_{}'.format(timestamp, \"quantizationattempt\")\n",
    "torch.save(alexnet.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acef840-1b43-4057-aa0f-5d2bae6631b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358ee41-5c01-49ec-93ee-ab0aa4381f7f",
   "metadata": {},
   "source": [
    "# Model Size Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e5992a1-0c8b-4579-ac7d-3146a177dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_model_size_change(alexnet, bit_length):\n",
    "    data_type_sizes = []\n",
    "    abs_max_sizes = []\n",
    "    count = 0\n",
    "    bits_in_fp32 = 8 + 23\n",
    "    for layer in [*alexnet.features,*alexnet.classifier]:\n",
    "        count += 1 \n",
    "        # curr_layer_path = curr_path / f'layer{count}.npy' \n",
    "        curr_data_size = 0\n",
    "        curr_abs_max_size = 0\n",
    "        try:\n",
    "            data_type_sizes.append(0)\n",
    "            abs_max_sizes.append(0)\n",
    "            if len(layer.weight.shape) == 4:\n",
    "                weights = layer.weight.detach()\n",
    "                # print(f'Layer {count}')# weights shape pre-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                for filter in range(0, weights.shape[0]):\n",
    "                    # print(f'Filter num {filter}')\n",
    "                    for channel in range(0, weights.shape[1]):\n",
    "                        # print(f'Channel num {channel}')\n",
    "                        # print(layer.weight[filter,channel])\n",
    "                        data_type_sizes[-1] += weights[filter,channel].numel()\n",
    "                        abs_max_sizes[-1] += weights[filter,channel].shape[0]\n",
    "                        # for row in range(0,weights.shape[2]):\n",
    "                        #     weights[filter,channel, row] = quantize_dequantize_dt(weights[filter,channel,row])\n",
    "                        # print(f'Finish window')\n",
    "                # print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                # layer.weight = nn.parameter.Parameter(weights)\n",
    "                # print(f'Layer {count} weights shape post-quantization: {weights.shape}\\nWeights: {weights}')\n",
    "                # layer.weight = nn.parameter.Parameter(weights)\n",
    "            else:\n",
    "                weights = layer.weight.detach()\n",
    "                # print(f'Layer {count}')# weights shape pre-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "                data_type_sizes[-1] += weights.numel()\n",
    "                abs_max_sizes[-1] += weights.shape[0]\n",
    "                # print(weights.shape)\n",
    "                # for row in tqdm(range(0,weights.shape[0])):\n",
    "                #     weights[row] = quantize_dequantize_dt(weights[row])\n",
    "                # layer.weight = nn.parameter.Parameter(weights)\n",
    "                # print(f'Layer {count} weights shape post-quantization: {layer.weight.shape}\\nWeights: {weights}')\n",
    "                # print(layer.weight)\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "    return {'data_type_counts': np.array(data_type_sizes), 'data_type_sizes': np.array(data_type_sizes) * bit_length, 'abs_max_counts': np.array(abs_max_sizes), 'abs_max_sizes': np.array(abs_max_sizes) * bits_in_fp32,\n",
    "           'data_type_sizes_original': np.array(data_type_sizes) * bits_in_fp32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd9feaff-aa25-483e-a060-27b9edf8720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_to_mb(bits):\n",
    "    return bits / 8000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b1cacc0-2181-443b-a7bd-1062cffabccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_size(model, bit_len):\n",
    "    bits_in_fp32 = 8 + 23\n",
    "    results = estimate_model_size_change(model, bit_len)\n",
    "    data_type_size = results['data_type_sizes'].sum()\n",
    "    abs_max_size = results['abs_max_sizes'].sum()\n",
    "    dt_counts = results['data_type_counts'].sum()\n",
    "    display(Markdown(f'## {bit_len} bits'))\n",
    "    print(f'{data_type_size} bits to represent the {bit_len} quantized dt and {abs_max_size} bits to represent the maxes')\n",
    "    print(f'{bits_to_mb(data_type_size)} mb to represent the {bit_len} quantized dt and {bits_to_mb(abs_max_size)} mb to represent the maxes')\n",
    "    print(f'\\nOriginal Model Size: {bits_to_mb( dt_counts * bits_in_fp32)} MB')\n",
    "    print(f'Quantized Model Size: {bits_to_mb( data_type_size +abs_max_size)} MB')\n",
    "    print(f'This is a {bits_to_mb( dt_counts * bits_in_fp32) / (bits_to_mb(data_type_size)+bits_to_mb(abs_max_size))}x decrease in size')\n",
    "    return (bits_to_mb(data_type_size)+bits_to_mb(abs_max_size)), bits_to_mb(data_type_size),bits_to_mb(abs_max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3eb40df7-0e6b-4b72-93c6-f42278d87c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_model(model):\n",
    "    flattened_model = torch.tensor([])\n",
    "    for layer in [*model.features,*model.classifier]:\n",
    "        try:\n",
    "            weights = layer.weight.detach()\n",
    "            flattened_model = torch.concatenate((flattened_model, weights.flatten()))\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "    return flattened_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ff50346-3a05-4751-981a-2587585d4e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Elijah/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355374592 44.421824\n",
      "710749184 88.843648\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "    \n",
    "model.classifier[4] = nn.Linear(4096,1024)\n",
    "model.classifier[6] = nn.Linear(1024,10)\n",
    "\n",
    "model.load_state_dict(torch.load(f'./model_20240603_151633_final_frozen_alexnet',map_location=device))\n",
    "model.eval()\n",
    "\n",
    "flattened_alexnet = flatten_model(alexnet)\n",
    "print(flattened_alexnet.shape[0] * 8, bits_to_mb(flattened_alexnet.shape[0] * 8))\n",
    "print(flattened_alexnet.shape[0] * 16, bits_to_mb(flattened_alexnet.shape[0] * 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ce33a-b736-4c43-ad8b-9b0bfc2dc7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
